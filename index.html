<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Parallel Computing Final Exam</title>
    <style>
    :root {
        --bg-color: #f8fafc;
        --text-color: #161b24;
        --primary-color: #2a676f;
        --secondary-color: #3a8893;
        --card-bg: rgba(255, 255, 255, 0.95);
        --border-color: rgba(224, 224, 224, 0.7);
        --option-bg: #f8fafc;
        --option-hover-bg: #e2e8f0;
        --quiz-header-bg: linear-gradient(135deg, #2a676f 0%, #3a8893 100%);
        --correct-bg: #e8f5e9;
        --correct-border: #43a047;
        --incorrect-bg: #ffebee;
        --incorrect-border: #e53935;
        --gradient-color: rgba(42, 103, 111, 0.03);
        --background-pattern: url("data:image/svg+xml,%3Csvg width='52' height='26' viewBox='0 0 52 26' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='%232a676f' fill-opacity='0.05'%3E%3Cpath d='M10 10c0-2.21-1.79-4-4-4-3.314 0-6-2.686-6-6h2c0 2.21 1.79 4 4 4 3.314 0 6 2.686 6 6 0 2.21 1.79 4 4 4 3.314 0 6 2.686 6 6 0 2.21 1.79 4 4 4v2c-3.314 0-6-2.686-6-6 0-2.21-1.79-4-4-4-3.314 0-6-2.686-6-6zm25.464-1.95l8.486 8.486-1.414 1.414-8.486-8.486 1.414-1.414z' /%3E%3C/g%3E%3C/svg%3E");
        --slide-bg: #ffffff;
        --slide-header: #2a676f;
        --slide-border: #d1d5db;
        --grammar-bg: #f1f5f9;
        --grammar-border: #cbd5e1;
        --glass-bg: rgba(42, 103, 111, 0.1);
        --glass-border: rgba(42, 103, 111, 0.2);
        --glass-shadow: 0 4px 20px rgba(42, 103, 111, 0.15);
        --button-primary-bg: linear-gradient(135deg, #2a676f, #3a8893);
        --button-secondary-bg: linear-gradient(135deg, #a98a50, #c5a66a);
        --code-bg: #f1f5f9;
        --code-text: #1e293b;
        --expl-bg: #fffde7;
        --expl-border: #fbc02d;
        --expl-text: #5d4037;
    }

    [data-theme="dark"] {
        --bg-color: #1a202c;
        --text-color: #e2e8f0;
        --primary-color: #38b2ac;
        --secondary-color: #2a676f;
        --card-bg: rgba(26, 32, 44, 0.95);
        --border-color: rgba(74, 85, 104, 0.7);
        --option-bg: rgba(45, 55, 72, 0.5);
        --option-hover-bg: rgba(66, 153, 225, 0.1);
        --quiz-header-bg: linear-gradient(135deg, #2a676f 0%, #3a8893 100%);
        --correct-bg: rgba(72, 187, 120, 0.1);
        --correct-border: #48bb78;
        --incorrect-bg: rgba(245, 101, 101, 0.1);
        --incorrect-border: #f56565;
        --gradient-color: transparent;
        --background-pattern: none;
        --slide-bg: #2d3748;
        --slide-header: #38b2ac;
        --slide-border: #4a5568;
        --grammar-bg: #4a5568;
        --grammar-border: #718096;
        --glass-bg: rgba(56, 178, 172, 0.1);
        --glass-border: rgba(56, 178, 172, 0.2);
        --glass-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
        --button-primary-bg: linear-gradient(135deg, #38b2ac, #2a676f);
        --button-secondary-bg: linear-gradient(135deg, #f6ad55, #ed8936);
        --code-bg: #0f172a;
        --code-text: #e2e8f0;
        --expl-bg: rgba(251, 192, 45, 0.15);
        --expl-border: #fdd835;
        --expl-text: #fff9c4;
    }

    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
        font-family: 'Segoe UI', system-ui, sans-serif;
    }

    body {
        background-color: var(--bg-color);
        background-image: 
            linear-gradient(to right, var(--gradient-color) 1px, transparent 1px),
            linear-gradient(to bottom, var(--gradient-color) 1px, transparent 1px),
            var(--background-pattern);
        background-size: 
            40px 40px,
            40px 40px,
            52px 26px;
        color: var(--text-color);
        transition: background-color 0.3s ease, color 0.3s ease;
        line-height: 1.6;
        min-height: 100vh;
    }

    .quiz-container {
        max-width: 1200px;
        margin: 2rem auto;
        padding: 2rem;
        background: var(--card-bg);
        border-radius: 20px;
        box-shadow: 0 15px 50px rgba(0,0,0,0.1);
        border: 1px solid var(--border-color);
        backdrop-filter: blur(10px);
        position: relative;
        overflow: hidden;
    }

    .quiz-container::before {
        content: 'üíª‚ö°üîß';
        position: absolute;
        top: -50px;
        right: -50px;
        font-size: 120px;
        opacity: 0.05;
        transform: rotate(15deg);
        z-index: 0;
    }

    .quiz-header {
        text-align: center;
        font-size: 2.2rem;
        font-weight: 700;
        margin-bottom: 2rem;
        color: white;
        padding: 1.5rem;
        background: var(--quiz-header-bg);
        border-radius: 15px;
        box-shadow: 0 6px 20px rgba(42, 103, 111, 0.3);
        position: relative;
        overflow: hidden;
    }

    .quiz-header::after {
        content: 'üìò';
        position: absolute;
        right: 20px;
        top: 50%;
        transform: translateY(-50%);
        opacity: 0.15;
        font-size: 3rem;
    }

    .quiz-subtitle {
        text-align: center;
        font-size: 1.2rem;
        color: var(--text-color);
        margin-bottom: 1.5rem;
        padding: 1rem;
        background: var(--glass-bg);
        border-radius: 10px;
        border-left: 5px solid var(--primary-color);
    }

    .controls {
        text-align: center;
        margin-bottom: 2rem;
        display: flex;
        gap: 1rem;
        justify-content: center;
        flex-wrap: wrap;
        padding: 1.5rem;
        background: var(--glass-bg);
        backdrop-filter: blur(10px);
        border-radius: 15px;
        border: 1px solid var(--glass-border);
        box-shadow: var(--glass-shadow);
    }

    .btn {
        display: inline-flex;
        align-items: center;
        justify-content: center;
        padding: 0.9rem 1.8rem;
        background: var(--button-primary-bg);
        color: white;
        border: none;
        border-radius: 12px;
        font-size: 1rem;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        gap: 8px;
        box-shadow: 0 4px 12px rgba(42, 103, 111, 0.2);
        position: relative;
        overflow: hidden;
        min-width: 160px;
    }

    .btn::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
        transition: 0.5s;
    }

    .btn:hover {
        transform: translateY(-3px);
        box-shadow: 0 8px 20px rgba(42, 103, 111, 0.3);
    }

    .btn:hover::before {
        left: 100%;
    }

    .btn-secondary {
        background: var(--button-secondary-bg);
    }

    .btn-icon {
        font-size: 1.1rem;
    }

    .question-group {
        margin-bottom: 3rem;
        padding: 2rem;
        background: var(--card-bg);
        border: 2px solid var(--primary-color);
        border-radius: 20px;
        box-shadow: 0 8px 30px rgba(0, 0, 0, 0.1);
        position: relative;
        overflow: hidden;
    }

    .grouped-questions .question {
        margin-bottom: 1.5rem;
        padding: 1.8rem;
        background: var(--card-bg);
        border: 1px solid var(--border-color);
        border-radius: 15px;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        box-shadow: 0 4px 12px rgba(0,0,0,0.05);
    }

    .grouped-questions .question:hover {
        transform: translateX(5px);
        border-color: var(--primary-color);
        box-shadow: 6px 6px 20px rgba(42, 103, 111, 0.1);
    }

    .question-group::before {
        content: 'üìö';
        position: absolute;
        top: 20px;
        right: 20px;
        font-size: 2.5rem;
        opacity: 0.1;
    }

    .group-header {
        margin-bottom: 2rem;
        padding-bottom: 1.5rem;
        border-bottom: 3px dashed var(--primary-color);
    }

    .group-header h3 {
        color: var(--primary-color);
        font-size: 1.4rem;
        margin-bottom: 1rem;
    }

    .grouped-questions {
        display: flex;
        flex-direction: column;
        gap: 1.5rem;
    }

    .grouped-questions .question h4 {
        color: var(--primary-color) !important;
        font-size: 1.3rem !important;
        font-weight: 700;
        margin-bottom: 1rem;
        padding-left: 10px;
        border-left: 4px solid var(--primary-color);
    }

    .question {
        margin-bottom: 2.5rem;
        padding: 1.8rem;
        background: var(--card-bg);
        border: 1px solid var(--border-color);
        border-radius: 15px;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        position: relative;
        overflow: visible;
        box-shadow: 0 4px 12px rgba(0,0,0,0.05);
    }

    .question:hover {
        transform: translateX(5px);
        border-color: var(--primary-color);
        box-shadow: 6px 6px 20px rgba(42, 103, 111, 0.1);
    }

    .question h3 {
        color: var(--primary-color);
        margin-bottom: 1rem;
        font-size: 1.3rem;
        position: relative;
        padding-left: 10px;
        border-left: 4px solid var(--primary-color);
    }

    .options label {
        display: flex;
        align-items: center;
        padding: 1.1rem;
        margin: 0.8rem 0;
        background: var(--option-bg);
        border-radius: 12px;
        cursor: pointer;
        transition: all 0.2s ease;
        gap: 12px;
        border: 2px solid transparent;
        position: relative;
        z-index: 2;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }

    .options label:hover {
        background: var(--option-hover-bg);
        transform: translateX(5px);
        box-shadow: 4px 4px 12px rgba(42, 103, 111, 0.1);
        border-color: var(--primary-color);
    }

    .options input[type="radio"] {
        margin-left: 1rem;
        transform: scale(1.3);
        accent-color: var(--primary-color);
        cursor: pointer;
    }

    .answer-box {
        margin-top: 1.5rem;
        margin-bottom: 0.5rem;
        padding: 1.2rem;
        border-radius: 12px;
        display: none;
        animation: fadeIn 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        font-weight: 500;
        letter-spacing: 0.3px;
        position: relative;
        z-index: 2;
        border-left: 5px solid;
        white-space: normal;
        word-wrap: break-word;
        overflow-wrap: break-word;
    }

    .correct {
        background: var(--correct-bg);
        border-color: var(--correct-border);
        color: var(--text-color);
    }

    .incorrect {
        background: var(--incorrect-bg);
        border-color: var(--incorrect-border);
        color: var(--text-color);
    }

    .code-block, .formula-block, .graph-block {
        background: var(--code-bg) !important;
        color: var(--code-text) !important;
        border: 1px solid var(--border-color);
        border-radius: 8px;
        padding: 1.5rem;
        margin: 1rem 0;
        font-family: 'Consolas', 'Courier New', monospace;
    }

    .code-block pre, .formula-block pre, .graph-block pre {
        white-space: pre-wrap !important;
        word-wrap: break-word !important;
        word-break: break-word !important;
        overflow-x: hidden;
        margin: 0;
        font-size: 0.95rem;
        line-height: 1.5;
    }

    .formula-block {
        background: #fff8e1 !important;
        border-color: #ffd54f;
    }

    .graph-block {
        background: #e8f5e9 !important;
        border-color: #81c784;
    }

    [data-theme="dark"] .formula-block {
        background: rgba(255, 193, 7, 0.1) !important;
        border-color: #ffb300;
    }

    [data-theme="dark"] .graph-block {
        background: rgba(76, 175, 80, 0.1) !important;
        border-color: #4caf50;
    }

    .explanation-container {
        display: flex;
        flex-direction: column;
        align-items: flex-start;
        gap: 8px;
        margin-top: 8px;
        animation: fadeIn 0.3s ease;
    }

    .btn-explanation {
        background: var(--glass-bg);
        border: 1px solid var(--primary-color);
        color: var(--primary-color);
        padding: 6px 14px;
        border-radius: 6px;
        cursor: pointer;
        font-size: 0.9rem;
        font-weight: 600;
        display: inline-flex;
        align-items: center;
        gap: 6px;
        transition: all 0.2s ease;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }

    .explanation-content {
        background: var(--expl-bg);
        border-left: 4px solid var(--expl-border);
        color: var(--expl-text);
        border-radius: 8px;
        padding: 15px;
        width: 100%;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        font-size: 0.95rem;
        line-height: 1.6;
        position: relative;
    }

    .explanation-content::before {
        content: 'üí°';
        margin-right: 8px;
    }

    .btn-show-correct {
        background: transparent;
        border: 1px solid var(--incorrect-border);
        color: var(--incorrect-border);
        padding: 6px 14px;
        border-radius: 20px;
        cursor: pointer;
        font-size: 0.9rem;
        font-weight: 600;
        margin-left: 10px;
        transition: all 0.2s ease;
        display: inline-block;
    }

    .btn-show-correct:hover {
        background: var(--incorrect-bg);
        transform: translateY(-1px);
    }

    .slides-section {
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 3px dashed var(--primary-color);
    }

    .slides-header {
        background: var(--quiz-header-bg);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        margin: 2.5rem 0;
        font-size: 1.8rem;
        font-weight: 700;
        text-align: center;
        box-shadow: 0 6px 20px rgba(42, 103, 111, 0.3);
        position: relative;
        overflow: hidden;
    }

    .slides-header::after {
        content: 'üìö';
        position: absolute;
        right: 20px;
        top: 50%;
        transform: translateY(-50%);
        opacity: 0.15;
        font-size: 2.5rem;
    }

    .pdf-controls {
        display: flex;
        justify-content: center;
        gap: 1.2rem;
        margin-bottom: 2rem;
        flex-wrap: wrap;
    }

    .pdf-btn {
        padding: 0.9rem 1.8rem;
        background: var(--glass-bg);
        border: 1px solid var(--glass-border);
        border-radius: 10px;
        color: var(--text-color);
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s ease;
        display: flex;
        align-items: center;
        gap: 8px;
        backdrop-filter: blur(5px);
    }

    .pdf-btn:hover {
        background: var(--button-primary-bg);
        color: white;
        transform: translateY(-2px);
    }

    .pdf-btn.active {
        background: var(--button-primary-bg);
        color: white;
        border-color: transparent;
        box-shadow: 0 4px 12px rgba(42, 103, 111, 0.3);
    }

    .pdf-viewer-container {
        background: var(--slide-bg);
        border-radius: 15px;
        overflow: hidden;
        margin-bottom: 2rem;
        border: 1px solid var(--border-color);
        box-shadow: 0 15px 40px rgba(0,0,0,0.15);
        min-height: 800px;
        height: 70vh;
        display: flex;
        flex-direction: column;
    }

    .pdf-viewer-header {
        background: var(--quiz-header-bg);
        color: white;
        padding: 1rem 1.5rem;
        display: flex;
        justify-content: space-between;
        align-items: center;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        flex-shrink: 0;
    }

    .pdf-viewer-title {
        font-size: 1.2rem;
        font-weight: 600;
    }

    .pdf-controls-small {
        display: flex;
        gap: 0.5rem;
    }

    .pdf-nav-btn {
        background: rgba(255, 255, 255, 0.2);
        color: white;
        border: 1px solid rgba(255, 255, 255, 0.4);
        border-radius: 8px;
        padding: 0.5rem 1rem;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        font-size: 1rem;
        transition: all 0.3s ease;
        min-width: 50px;
    }

    .pdf-nav-btn:hover {
        background: rgba(255, 255, 255, 0.3);
        transform: scale(1.05);
    }

    .pdf-frame-container {
        flex-grow: 1;
        position: relative;
        overflow: hidden;
        min-height: 600px;
    }

    .pdf-frame {
        width: 100%;
        height: 100%;
        border: none;
        min-height: 600px;
    }

    .pdf-loading {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        background: var(--slide-bg);
        z-index: 10;
    }

    .pdf-loading-spinner {
        width: 50px;
        height: 50px;
        border: 5px solid var(--border-color);
        border-top: 5px solid var(--primary-color);
        border-radius: 50%;
        animation: spin 1s linear infinite;
        margin-bottom: 1rem;
    }

    .pdf-loading-text {
        color: var(--text-color);
        font-weight: 500;
    }

    .mobile-pdf-list {
        display: none;
        flex-direction: column;
        gap: 1rem;
        margin-bottom: 2rem;
    }

    .mobile-pdf-item {
        background: var(--card-bg);
        border: 1px solid var(--border-color);
        border-radius: 12px;
        padding: 1.2rem;
        display: flex;
        justify-content: space-between;
        align-items: center;
        box-shadow: 0 4px 12px rgba(0,0,0,0.05);
        transition: all 0.3s ease;
    }

    .mobile-pdf-item:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0,0,0,0.1);
    }

    .mobile-pdf-info {
        display: flex;
        align-items: center;
        gap: 1rem;
    }

    .mobile-pdf-icon {
        font-size: 2rem;
    }

    .mobile-pdf-details {
        display: flex;
        flex-direction: column;
    }

    .mobile-pdf-name {
        font-weight: 600;
        font-size: 1.1rem;
        color: var(--text-color);
    }

    .mobile-pdf-size {
        font-size: 0.9rem;
        color: var(--text-color);
        opacity: 0.7;
    }

    .mobile-pdf-actions {
        display: flex;
        gap: 0.5rem;
        flex-wrap: wrap;
    }

    .mobile-pdf-btn {
        padding: 0.5rem 1rem;
        border-radius: 8px;
        border: none;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s ease;
        white-space: nowrap;
    }

    .mobile-pdf-btn.open-btn {
        background: var(--button-primary-bg);
        color: white;
    }

    .mobile-pdf-btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }

    .quiz-progress {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 2rem;
        padding: 1rem;
        background: var(--glass-bg);
        border-radius: 10px;
        border: 1px solid var(--glass-border);
    }

    .progress-bar {
        flex-grow: 1;
        height: 10px;
        background: var(--border-color);
        border-radius: 5px;
        margin: 0 1rem;
        overflow: hidden;
    }

    .progress-fill {
        height: 100%;
        background: var(--primary-color);
        border-radius: 5px;
        transition: width 0.3s ease;
    }

    .progress-text {
        font-weight: 600;
        color: var(--primary-color);
        white-space: nowrap;
    }

    .footer-note {
        text-align: center;
        margin: 3rem 0 1rem;
        padding: 1.5rem;
        color: var(--primary-color);
        font-size: 1.1rem;
        border-top: 2px solid rgba(42, 103, 111, 0.2);
        opacity: 0.9;
        font-weight: 600;
        background: var(--glass-bg);
        border-radius: 15px;
        backdrop-filter: blur(5px);
    }

    [data-theme="dark"] .footer-note {
        color: var(--secondary-color);
        border-color: rgba(169, 138, 80, 0.3);
    }

    .hidden {
        display: none;
    }

    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(15px); }
        to { opacity: 1; transform: translateY(0); }
    }

    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }

    @media (max-width: 1024px) {
        .quiz-container {
            margin: 1rem;
            padding: 1.5rem;
        }
        
        .quiz-header, .slides-header {
            font-size: 1.7rem;
            padding: 1.2rem;
        }
        
        .pdf-viewer-container {
            min-height: 600px;
            height: 65vh;
        }
    }

    @media (max-width: 768px) {
        .controls {
            flex-direction: row;
            flex-wrap: wrap;
            gap: 10px;
            padding: 1rem;
        }
        
        .btn {
            width: auto;
            flex: 1 1 calc(50% - 10px);
            margin: 0;
            min-width: 120px;
            padding: 0.8rem;
            font-size: 0.9rem;
        }
        
        .pdf-controls {
            display: none !important;
        }
        
        .desktop-viewer {
            display: none !important;
        }
        
        .mobile-pdf-list {
            display: flex;
        }
        
        .pdf-viewer-container {
            min-height: 500px;
            height: 60vh;
        }
        
        .mobile-pdf-item {
            flex-direction: column;
            text-align: center;
            gap: 1rem;
        }
        
        .mobile-pdf-info {
            flex-direction: column;
            text-align: center;
        }
        
        .mobile-pdf-actions {
            width: 100%;
            justify-content: center;
        }
        
        .mobile-pdf-btn {
            flex: 1;
            max-width: 120px;
        }
    }

    @media (min-width: 769px) {
        .mobile-pdf-list {
            display: none !important;
        }
        
        .desktop-viewer {
            display: flex !important;
        }
    }

    @media (max-width: 480px) {
        .quiz-header, .slides-header {
            font-size: 1.4rem;
            padding: 1rem;
        }
        
        .pdf-viewer-container {
            min-height: 400px;
            height: 55vh;
        }
        
        .pdf-nav-btn {
            padding: 0.4rem 0.8rem;
            min-width: 45px;
        }
    }
    </style>
</head>
<body>
    <div class="quiz-container">
        <div class="quiz-header">
            Parallel Computing Final Exam
        </div>

        <div class="quiz-progress">
            <div class="progress-text">Quiz Progress:</div>
            <div class="progress-bar">
                <div class="progress-fill" id="quiz-progress" style="width: 0%"></div>
            </div>
            <div class="progress-text"><span id="answered-count">0</span>/129 Answered</div>
        </div>
        
        <div class="controls">
            <button class="btn" onclick="resetQuiz()">
                <span class="btn-icon">üîÑ</span> Reset Quiz
            </button>
            <button class="btn" onclick="showAllAnswers()">
                <span class="btn-icon">üëÅÔ∏è</span> Show All Answers
            </button>
            <button class="btn" onclick="hideAllAnswers()">
                <span class="btn-icon">üôà</span> Hide All Answers
            </button>
            <button class="btn btn-secondary" id="themeToggle" onclick="toggleTheme()">
                <span class="btn-icon">üåô</span> Dark Mode
            </button>
            <button class="btn btn-secondary" id="slidesToggle" onclick="toggleSlides()">
                <span class="btn-icon">üìö</span> ÿ≥ŸÑÿßŸäÿØÿßÿ™ ÿßŸÑŸÖÿßÿØÿ©
            </button>
        </div>

        <!-- Questions Section -->
        <div id="questions-section">
            <!-- Question 1 -->
            <div class="question">
                <h3>1. Which statement about the impact of multicore processors on serial programs is incorrect?</h3>
                <div class="options">
                    <label><input type="radio" name="q1" value="a"> a) Multicore processors inherently enhance the performance of serial programs due to multiple cores.</label>
                    <label><input type="radio" name="q1" value="b"> b) Multicore processors support increased multitasking capabilities, benefiting parallelizable tasks.</label>
                    <label><input type="radio" name="q1" value="c"> c) Each core can potentially execute a different task simultaneously, enhancing performance for multitasked environments.</label>
                    <label><input type="radio" name="q1" value="d"> d) Multicore processors provide more processing power without proportionally increasing the clock frequency, primarily benefiting parallelized tasks.</label>
                </div>
                <div class="answer-box" id="answer1" data-correct-answer="a" data-explanation="Multicore processors do NOT inherently enhance serial programs. Serial programs run on a single core, so additional cores remain unused. Only parallel programs or multitasking scenarios benefit from multiple cores.">
                    Correct Answer: a<br><br><em>Explanation: Multicore processors do NOT inherently enhance serial programs. Serial programs run on a single core, so additional cores remain unused. Only parallel programs or multitasking scenarios benefit from multiple cores.</em>
                </div>
            </div>

            <!-- Question 2 -->
            <div class="question">
                <h3>2. For what reason is the demand for increasing computational power essential?</h3>
                <div class="options">
                    <label><input type="radio" name="q2" value="a"> a) Reducing the size of computing devices</label>
                    <label><input type="radio" name="q2" value="b"> b) Tackling more complex and larger scale problems</label>
                    <label><input type="radio" name="q2" value="c"> c) Decreasing the cost of data storage</label>
                    <label><input type="radio" name="q2" value="d"> d) Increasing the battery life of devices</label>
                </div>
                <div class="answer-box" id="answer2" data-correct-answer="b" data-explanation="Increased computational power enables solving increasingly complex problems in scientific research, AI, simulations, and big data analysis that were previously infeasible.">
                    Correct Answer: b<br><br><em>Explanation: Increased computational power enables solving increasingly complex problems in scientific research, AI, simulations, and big data analysis that were previously infeasible.</em>
                </div>
            </div>

            <!-- Question 3 -->
            <div class="question">
                <h3>3. What does synchronization ensure in a parallel computing environment?</h3>
                <div class="options">
                    <label><input type="radio" name="q3" value="a"> a) Each processor operates at maximum efficiency independently.</label>
                    <label><input type="radio" name="q3" value="b"> b) All processors can perform tasks without any form of communication.</label>
                    <label><input type="radio" name="q3" value="c"> c) Processors cooperate without overwriting each other's results.</label>
                    <label><input type="radio" name="q3" value="d"> d) Tasks are executed in a strictly sequential order.</label>
                </div>
                <div class="answer-box" id="answer3" data-correct-answer="c" data-explanation="Synchronization coordinates parallel processes to maintain data consistency, prevent race conditions, and ensure correct program execution when multiple processors access shared resources.">
                    Correct Answer: c<br><br><em>Explanation: Synchronization coordinates parallel processes to maintain data consistency, prevent race conditions, and ensure correct program execution when multiple processors access shared resources.</em>
                </div>
            </div>

            <!-- Question 4 -->
            <div class="question">
                <h3>4. What is the main function of the program counter in a CPU?</h3>
                <div class="options">
                    <label><input type="radio" name="q4" value="a"> a) To store the results of arithmetic operations</label>
                    <label><input type="radio" name="q4" value="b"> b) To direct the operational flow of the program</label>
                    <label><input type="radio" name="q4" value="c"> c) To maintain the address of the next instruction to be executed</label>
                    <label><input type="radio" name="q4" value="d"> d) To manage the communication between the CPU and peripheral devices</label>
                </div>
                <div class="answer-box" id="answer4" data-correct-answer="c" data-explanation="The program counter (PC) is a special register that holds the memory address of the next instruction to fetch and execute, controlling the flow of program execution.">
                    Correct Answer: c<br><br><em>Explanation: The program counter (PC) is a special register that holds the memory address of the next instruction to fetch and execute, controlling the flow of program execution.</em>
                </div>
            </div>

            <!-- Question 5 -->
            <div class="question">
                <h3>5. Instruction Level Parallelism (ILP) aims to increase processor performance by:</h3>
                <div class="options">
                    <label><input type="radio" name="q5" value="a"> a) Reducing the need for multithreading</label>
                    <label><input type="radio" name="q5" value="b"> b) Executing multiple instructions in parallel within a single program</label>
                    <label><input type="radio" name="q5" value="c"> c) Decreasing the cache size to speed up access</label>
                    <label><input type="radio" name="q5" value="d"> d) Executing multiple threads concurrently on one or more cores</label>
                </div>
                <div class="answer-box" id="answer5" data-correct-answer="b" data-explanation="ILP exploits parallel execution of instructions within a single thread/process using techniques like pipelining, superscalar execution, and out-of-order execution.">
                    Correct Answer: b<br><br><em>Explanation: ILP exploits parallel execution of instructions within a single thread/process using techniques like pipelining, superscalar execution, and out-of-order execution.</em>
                </div>
            </div>

            <!-- Question 6 -->
            <div class="question">
                <h3>6. Which type of memory architecture allows all processors to access all memory as a global address space?</h3>
                <div class="options">
                    <label><input type="radio" name="q6" value="a"> a) Distributed memory architecture</label>
                    <label><input type="radio" name="q6" value="b"> b) Shared memory architecture</label>
                    <label><input type="radio" name="q6" value="c"> c) Hybrid memory architecture</label>
                    <label><input type="radio" name="q6" value="d"> d) Local memory architecture</label>
                </div>
                <div class="answer-box" id="answer6" data-correct-answer="b" data-explanation="Shared memory architecture provides a single global address space that all processors can access directly, simplifying programming but requiring synchronization mechanisms.">
                    Correct Answer: b<br><br><em>Explanation: Shared memory architecture provides a single global address space that all processors can access directly, simplifying programming but requiring synchronization mechanisms.</em>
                </div>
            </div>

            <!-- Question 7 -->
            <div class="question">
                <h3>7. How does a vector processor handle data compared to a conventional CPU?</h3>
                <div class="options">
                    <label><input type="radio" name="q7" value="a"> a) Operates on individual data elements.</label>
                    <label><input type="radio" name="q7" value="b"> b) Processes arrays of data simultaneously.</label>
                    <label><input type="radio" name="q7" value="c"> c) Executes single data elements in parallel.</label>
                    <label><input type="radio" name="q7" value="d"> d) Uses a single data element per instruction.</label>
                </div>
                <div class="answer-box" id="answer7" data-correct-answer="b" data-explanation="Vector processors use SIMD (Single Instruction Multiple Data) to apply the same operation to multiple data elements (arrays/vectors) simultaneously, ideal for scientific computing.">
                    Correct Answer: b<br><br><em>Explanation: Vector processors use SIMD (Single Instruction Multiple Data) to apply the same operation to multiple data elements (arrays/vectors) simultaneously, ideal for scientific computing.</em>
                </div>
            </div>

            <!-- Question 8 -->
            <div class="question">
                <h3>8. What is the main advantage of using GPU for parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q8" value="a"> a) GPUs primarily enhance serial computation.</label>
                    <label><input type="radio" name="q8" value="b"> b) GPUs are less effective than CPUs in handling multiple data streams.</label>
                    <label><input type="radio" name="q8" value="c"> c) GPUs can process many pieces of data simultaneously, enhancing parallelism.</label>
                    <label><input type="radio" name="q8" value="d"> d) GPUs use a complex set of instructions compared to CPUs.</label>
                </div>
                <div class="answer-box" id="answer8" data-correct-answer="c" data-explanation="GPUs have thousands of simpler cores optimized for parallel data processing, making them excellent for graphics rendering, machine learning, and scientific simulations where massive parallelism is needed.">
                    Correct Answer: c<br><br><em>Explanation: GPUs have thousands of simpler cores optimized for parallel data processing, making them excellent for graphics rendering, machine learning, and scientific simulations where massive parallelism is needed.</em>
                </div>
            </div>

            <!-- Question 9 -->
            <div class="question">
                <h3>9. What best characterizes the cache coherence problem in multicore systems?</h3>
                <div class="options">
                    <label><input type="radio" name="q9" value="a"> a) Cores can operate independently without ever needing to synchronize data in their caches.</label>
                    <label><input type="radio" name="q9" value="b"> b) Only one core at a time is allowed to write to any shared cache line, managed through coherence protocols.</label>
                    <label><input type="radio" name="q9" value="c"> c) It is essential for a write made by one core to be visible to all other cores, facilitated by coherence protocols.</label>
                    <label><input type="radio" name="q9" value="d"> d) Cores maintain completely independent views of shared data without any overlap.</label>
                </div>
                <div class="answer-box" id="answer9" data-correct-answer="c" data-explanation="Cache coherence ensures that all processors see a consistent view of shared memory. When one core updates data, other cores must see the updated value, not stale cached copies.">
                    Correct Answer: c<br><br><em>Explanation: Cache coherence ensures that all processors see a consistent view of shared memory. When one core updates data, other cores must see the updated value, not stale cached copies.</em>
                </div>
            </div>

            <!-- Question 10 -->
            <div class="question">
                <h3>10. How is false sharing a performance problem in parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q10" value="a"> a) It increases the computation power of applications.</label>
                    <label><input type="radio" name="q10" value="b"> b) It allows for faster memory access times.</label>
                    <label><input type="radio" name="q10" value="c"> c) It causes threads to read slightly stale values without affecting performance.</label>
                    <label><input type="radio" name="q10" value="d"> d) It results in unnecessary invalidations and cache reloads.</label>
                </div>
                <div class="answer-box" id="answer10" data-correct-answer="d" data-explanation="False sharing occurs when threads on different processors modify different variables that happen to reside on the same cache line, causing unnecessary cache invalidations and reloads, degrading performance.">
                    Correct Answer: d<br><br><em>Explanation: False sharing occurs when threads on different processors modify different variables that happen to reside on the same cache line, causing unnecessary cache invalidations and reloads, degrading performance.</em>
                </div>
            </div>

            <!-- Question 11 -->
            <div class="question">
                <h3>11. What is the primary purpose of a write-back cache?</h3>
                <div class="options">
                    <label><input type="radio" name="q11" value="a"> a) To immediately write modifications to the main memory.</label>
                    <label><input type="radio" name="q11" value="b"> b) To delay writing modifications to the main memory until necessary.</label>
                    <label><input type="radio" name="q11" value="c"> c) To prevent any modifications from being written to the main memory.</label>
                    <label><input type="radio" name="q11" value="d"> d) To write modifications only on system shutdown.</label>
                </div>
                <div class="answer-box" id="answer11" data-correct-answer="b" data-explanation="Write-back caches only update main memory when the cache line is evicted or explicitly flushed, reducing memory traffic and improving performance by batching writes.">
                    Correct Answer: b<br><br><em>Explanation: Write-back caches only update main memory when the cache line is evicted or explicitly flushed, reducing memory traffic and improving performance by batching writes.</em>
                </div>
            </div>

            <!-- Question 12 -->
            <div class="question">
                <h3>12. In a distributed memory system, how is data typically accessed across processors?</h3>
                <div class="options">
                    <label><input type="radio" name="q12" value="a"> a) Each processor accesses global memory directly.</label>
                    <label><input type="radio" name="q12" value="b"> b) Processors communicate via shared memory.</label>
                    <label><input type="radio" name="q12" value="c"> c) Processors send messages to access data in other processors' memory.</label>
                    <label><input type="radio" name="q12" value="d"> d) No communication is required for accessing data.</label>
                </div>
                <div class="answer-box" id="answer12" data-correct-answer="c" data-explanation="In distributed memory systems, each processor has its own private memory. Processors communicate explicitly via message passing (e.g., MPI) to exchange data.">
                    Correct Answer: c<br><br><em>Explanation: In distributed memory systems, each processor has its own private memory. Processors communicate explicitly via message passing (e.g., MPI) to exchange data.</em>
                </div>
            </div>

            <!-- Question 13 -->
            <div class="question">
                <h3>13. What is a major limitation of using UMA (Uniform Memory Access) systems?</h3>
                <div class="options">
                    <label><input type="radio" name="q13" value="a"> a) Low latency</label>
                    <label><input type="radio" name="q13" value="b"> b) Easy implementation</label>
                    <label><input type="radio" name="q13" value="c"> c) High scalability</label>
                    <label><input type="radio" name="q13" value="d"> d) Limited scalability due to contention and limited memory bus bandwidth</label>
                </div>
                <div class="answer-box" id="answer13" data-correct-answer="d" data-explanation="UMA systems use a single shared bus or switch connecting all processors to memory, which becomes a bottleneck as processor count increases, limiting scalability.">
                    Correct Answer: d<br><br><em>Explanation: UMA systems use a single shared bus or switch connecting all processors to memory, which becomes a bottleneck as processor count increases, limiting scalability.</em>
                </div>
            </div>

            <!-- Question 14 -->
            <div class="question">
                <h3>14. Which type of interconnect is likely to replace buses in large shared-memory systems due to scalability issues?</h3>
                <div class="options">
                    <label><input type="radio" name="q14" value="a"> a) Crossbar switches</label>
                    <label><input type="radio" name="q14" value="b"> b) Ring topologies</label>
                    <label><input type="radio" name="q14" value="c"> c) Bus topologies</label>
                    <label><input type="radio" name="q14" value="d"> d) Direct interconnect meshes</label>
                </div>
                <div class="answer-box" id="answer14" data-correct-answer="a" data-explanation="Crossbar switches provide non-blocking connections between processors and memory modules, offering better scalability than buses but at higher cost and complexity.">
                    Correct Answer: a<br><br><em>Explanation: Crossbar switches provide non-blocking connections between processors and memory modules, offering better scalability than buses but at higher cost and complexity.</em>
                </div>
            </div>

            <!-- Question 15 -->
            <div class="question">
                <h3>15. What is the main challenge when implementing a NUMA system in terms of software?</h3>
                <div class="options">
                    <label><input type="radio" name="q15" value="a"> a) Simplifying the memory management to behave like UMA.</label>
                    <label><input type="radio" name="q15" value="b"> b) Managing the complexity of data placement and memory access patterns to minimize performance degradation from non-local memory accesses.</label>
                    <label><input type="radio" name="q15" value="c"> c) Ensuring all memory accesses are equally fast.</label>
                    <label><input type="radio" name="q15" value="d"> d) Reducing the physical size of the memory modules.</label>
                </div>
                <div class="answer-box" id="answer15" data-correct-answer="b" data-explanation="NUMA systems require careful data placement and thread scheduling to keep data close to the processor using it, minimizing costly remote memory accesses.">
                    Correct Answer: b<br><br><em>Explanation: NUMA systems require careful data placement and thread scheduling to keep data close to the processor using it, minimizing costly remote memory accesses.</em>
                </div>
            </div>

            <!-- Question 16 -->
            <div class="question">
                <h3>16. Considering false sharing, what is the main problem when two variables fit into the same cache line?</h3>
                <div class="options">
                    <label><input type="radio" name="q16" value="a"> a) Increases the cache hit rate dramatically.</label>
                    <label><input type="radio" name="q16" value="b"> b) Reduces the need for cache coherence protocols.</label>
                    <label><input type="radio" name="q16" value="c"> c) Causes performance degradation due to unnecessary data synchronization.</label>
                    <label><input type="radio" name="q16" value="d"> d) Simplifies the programming model by reducing cache management overhead.</label>
                </div>
                <div class="answer-box" id="answer16" data-correct-answer="c" data-explanation="When unrelated variables share a cache line, updates by one processor cause invalidations of the entire line for other processors, forcing frequent cache reloads even though the variables are independent.">
                    Correct Answer: c<br><br><em>Explanation: When unrelated variables share a cache line, updates by one processor cause invalidations of the entire line for other processors, forcing frequent cache reloads even though the variables are independent.</em>
                </div>
            </div>

            <!-- Question 17 -->
            <div class="question">
                <h3>17. Given the code <code>for (int i = 0; i < n; i++) {a[i] = b[i] + c[i];}</code>, how is the operation executed in a SIMD architecture?</h3>
                <div class="options">
                    <label><input type="radio" name="q17" value="a"> a) Each iteration of the loop is handled by a different processor sequentially.</label>
                    <label><input type="radio" name="q17" value="b"> b) All iterations of the loop are executed in parallel by different processors.</label>
                    <label><input type="radio" name="q17" value="c"> c) One processor executes all iterations of the loop simultaneously.</label>
                    <label><input type="radio" name="q17" value="d"> d) Multiple processors execute the same instruction on different pairs of elements simultaneously.</label>
                </div>
                <div class="answer-box" id="answer17" data-correct-answer="d" data-explanation="SIMD (Single Instruction Multiple Data) uses vector instructions to perform the same operation (addition) on multiple data pairs (a[i], b[i], c[i]) simultaneously, typically within a single processor's vector units.">
                    Correct Answer: d<br><br><em>Explanation: SIMD (Single Instruction Multiple Data) uses vector instructions to perform the same operation (addition) on multiple data pairs (a[i], b[i], c[i]) simultaneously, typically within a single processor's vector units.</em>
                </div>
            </div>

            <!-- Question 18 -->
            <div class="question">
                <h3>18. In a system using a write-invalidate protocol for cache coherence, what happens when one core updates the shared variable x = 10?</h3>
                <div class="options">
                    <label><input type="radio" name="q18" value="a"> a) The new value of x is immediately written to the main memory.</label>
                    <label><input type="radio" name="q18" value="b"> b) All copies of x in other caches are invalidated.</label>
                    <label><input type="radio" name="q18" value="c"> c) All cores update their local copies of x simultaneously.</label>
                    <label><input type="radio" name="q18" value="d"> d) The system stalls until all cores acknowledge the update.</label>
                </div>
                <div class="answer-box" id="answer18" data-correct-answer="b" data-explanation="In write-invalidate protocols, the writing core invalidates all other cached copies of the data. Other cores must fetch the updated value from memory or the writing core's cache when they next access it.">
                    Correct Answer: b<br><br><em>Explanation: In write-invalidate protocols, the writing core invalidates all other cached copies of the data. Other cores must fetch the updated value from memory or the writing core's cache when they next access it.</em>
                </div>
            </div>

            <!-- Question 19 -->
            <div class="question">
                <h3>19. Considering the potential for false sharing in the code "double array[16];", what method could effectively reduce its likelihood?</h3>
                <div class="options">
                    <label><input type="radio" name="q19" value="a"> a) Increase the size of the array elements.</label>
                    <label><input type="radio" name="q19" value="b"> b) Use padding between elements accessed by different threads.</label>
                    <label><input type="radio" name="q19" value="c"> c) Store each element of the array in separate cache lines.</label>
                    <label><input type="radio" name="q19" value="d"> d) Use a single thread to access the array.</label>
                </div>
                <div class="answer-box" id="answer19" data-correct-answer="b" data-explanation="Padding ensures that elements accessed by different threads fall into different cache lines. For example, align each element to cache line boundaries (typically 64 bytes) to prevent false sharing.">
                    Correct Answer: b<br><br><em>Explanation: Padding ensures that elements accessed by different threads fall into different cache lines. For example, align each element to cache line boundaries (typically 64 bytes) to prevent false sharing.</em>
                </div>
            </div>

            <!-- Question 20 -->
            <div class="question">
                <h3>20. How does the function <code>float process_pixel(float input) {return input * 0.5;}</code>, when executed on a GPU, demonstrate data parallelism?</h3>
                <div class="options">
                    <label><input type="radio" name="q20" value="a"> a) It processes multiple pixels in a single instruction cycle.</label>
                    <label><input type="radio" name="q20" value="b"> b) It applies the same operation to different pixels simultaneously.</label>
                    <label><input type="radio" name="q20" value="c"> c) It runs in multiple threads to utilize all available CPU cores.</label>
                    <label><input type="radio" name="q20" value="d"> d) It synchronizes pixel processing across different GPU cores.</label>
                </div>
                <div class="answer-box" id="answer20" data-correct-answer="b" data-explanation="GPUs execute the same kernel function (process_pixel) on thousands of data elements (pixels) concurrently, each in its own thread, achieving massive data parallelism.">
                    Correct Answer: b<br><br><em>Explanation: GPUs execute the same kernel function (process_pixel) on thousands of data elements (pixels) concurrently, each in its own thread, achieving massive data parallelism.</em>
                </div>
            </div>

            <!-- Question 21 -->
            <div class="question">
                <h3>21. What is a key difference in system architecture between cluster computing and grid computing regarding system homogeneity?</h3>
                <div class="options">
                    <label><input type="radio" name="q21" value="a"> a) Cluster computing requires homogeneous hardware and operating systems across all nodes, whereas grid computing can operate on heterogeneous systems.</label>
                    <label><input type="radio" name="q21" value="b"> b) Both cluster computing and grid computing require homogeneous systems.</label>
                    <label><input type="radio" name="q21" value="c"> c) Grid computing requires homogeneous systems, unlike cluster computing which can operate on heterogeneous systems.</label>
                    <label><input type="radio" name="q21" value="d"> d) Both cluster computing and grid computing thrive best on completely heterogeneous systems.</label>
                </div>
                <div class="answer-box" id="answer21" data-correct-answer="a" data-explanation="Clusters typically use identical or very similar nodes for performance and manageability. Grids connect diverse, geographically distributed resources with different architectures, operating systems, and ownership.">
                    Correct Answer: a<br><br><em>Explanation: Clusters typically use identical or very similar nodes for performance and manageability. Grids connect diverse, geographically distributed resources with different architectures, operating systems, and ownership.</em>
                </div>
            </div>

            <!-- Question 22 -->
            <div class="question">
                <h3>22. Consider a memory system where the latency is 200 milliseconds and the bandwidth is 800 MB/sec. How long will it take to transmit a message of 400 MB from the source to the destination, assuming no other delays?</h3>
                <div class="options">
                    <label><input type="radio" name="q22" value="a"> a) 200.5 seconds</label>
                    <label><input type="radio" name="q22" value="b"> b) 0.7 seconds</label>
                    <label><input type="radio" name="q22" value="c"> c) 0.5 seconds</label>
                    <label><input type="radio" name="q22" value="d"> d) 200.25 seconds</label>
                </div>
                <div class="answer-box" id="answer22" data-correct-answer="b" data-explanation="Total time = Latency + (Message Size / Bandwidth) = 0.2s + (400 MB / 800 MB/s) = 0.2s + 0.5s = 0.7 seconds">
                    Correct Answer: b<br><br><em>Explanation: Total time = Latency + (Message Size / Bandwidth) = 0.2s + (400 MB / 800 MB/s) = 0.2s + 0.5s = 0.7 seconds</em>
                </div>
            </div>

            <!-- Question 23 -->
            <div class="question">
                <h3>23. In an Omega network, how are data conflicts handled when two processors attempt to communicate with the same destination processor simultaneously?</h3>
                <div class="options">
                    <label><input type="radio" name="q23" value="a"> a) The network allows both communications to occur simultaneously without any conflict.</label>
                    <label><input type="radio" name="q23" value="b"> b) The network uses a dynamic routing algorithm to reroute one of the communications to a free path.</label>
                    <label><input type="radio" name="q23" value="c"> c) The network stalls one communication until the other is completed to manage the conflict.</label>
                    <label><input type="radio" name="q23" value="d"> d) The network uses a packet-switching technique where packets are queued at the destination until the conflict is resolved.</label>
                </div>
                <div class="answer-box" id="answer23" data-correct-answer="c" data-explanation="Omega networks are blocking multistage interconnection networks. When contention occurs, one message must wait (stall) until the conflicting resource becomes available.">
                    Correct Answer: c<br><br><em>Explanation: Omega networks are blocking multistage interconnection networks. When contention occurs, one message must wait (stall) until the conflicting resource becomes available.</em>
                </div>
            </div>

            <!-- Question 24 -->
            <div class="question">
                <h3>24. In a directory-based cache coherence system, when Core 0 updates a cache line that it previously read into its cache, what is the sequence of actions initiated to ensure coherence across the system, particularly involving Cores 2 and 4?</h3>
                <div class="options">
                    <label><input type="radio" name="q24" value="a"> a) Upon updating the cache line, Core 0 first consults the directory to determine which other cores share this cache line. The directory then directs Cores 2 and 4 to invalidate their corresponding cache lines.</label>
                    <label><input type="radio" name="q24" value="b"> b) Core 0 updates the cache line and independently sends a signal to Cores 2 and 4 to invalidate their cache lines without consulting the directory.</label>
                    <label><input type="radio" name="q24" value="c"> c) Core 0 updates the cache line and the directory autonomously updates its records without issuing any commands to other cores.</label>
                    <label><input type="radio" name="q24" value="d"> d) After updating, Core 0 logs the change in the directory. Cores 2 and 4 are required to periodically check the directory to decide if they need to invalidate their cache lines.</label>
                </div>
                <div class="answer-box" id="answer24" data-correct-answer="a" data-explanation="Directory-based coherence maintains a central directory tracking which cores cache each memory block. On a write, the directory identifies sharers and sends invalidation/update messages directly.">
                    Correct Answer: a<br><br><em>Explanation: Directory-based coherence maintains a central directory tracking which cores cache each memory block. On a write, the directory identifies sharers and sends invalidation/update messages directly.</em>
                </div>
            </div>

            <!-- Question 25 -->
            <div class="question">
                <h3>25. Consider a shared-memory system with two cores, where each double variable occupies 8 bytes and a cache line can store up to 64 bytes. If y has a length of m = 8 and y[0] is stored at the beginning of a cache line and y occupies one full cache line, what occurs when Core 0 and Core 1 simultaneously execute the statement y[i] += f(i,j)?</h3>
                <div class="options">
                    <label><input type="radio" name="q25" value="a"> a) The cache line remains stable and no additional memory fetches are required as the operations are confined to their respective cache lines.</label>
                    <label><input type="radio" name="q25" value="b"> b) Each execution of y[i] += f(i,j) by either core causes the cache line to be invalidated, forcing the other core to reload the updated cache line from memory for subsequent operations.</label>
                    <label><input type="radio" name="q25" value="c"> c) Both cores update the cache line without any need for synchronization, leading to data inconsistency.</label>
                    <label><input type="radio" name="q25" value="d"> d) The cache line is split dynamically between the cores to prevent any contention and invalidation.</label>
                </div>
                <div class="answer-box" id="answer25" data-correct-answer="b" data-explanation="Since the entire array y fits in one cache line, any write by either core invalidates the line in the other core's cache. This causes ping-ponging of the cache line between cores, a severe false sharing scenario.">
                    Correct Answer: b<br><br><em>Explanation: Since the entire array y fits in one cache line, any write by either core invalidates the line in the other core's cache. This causes ping-ponging of the cache line between cores, a severe false sharing scenario.</em>
                </div>
            </div>

            <!-- Question 26 -->
            <div class="question">
                <h3>26. In a system using a write-update protocol for cache coherence, what happens when one core updates the shared variable x = 10?</h3>
                <div class="options">
                    <label><input type="radio" name="q26" value="a"> a) The new value of x is written only to main memory.</label>
                    <label><input type="radio" name="q26" value="b"> b) All copies of x in other caches are updated with the new value.</label>
                    <label><input type="radio" name="q26" value="c"> c) All cores invalidate their local copies of x.</label>
                    <label><input type="radio" name="q26" value="d"> d) The system stalls until all cores acknowledge the update.</label>
                </div>
                <div class="answer-box" id="answer26" data-correct-answer="b" data-explanation="Write-update (broadcast) protocols immediately propagate new values to all caches holding the data. This reduces latency for subsequent reads but increases write traffic.">
                    Correct Answer: b<br><br><em>Explanation: Write-update (broadcast) protocols immediately propagate new values to all caches holding the data. This reduces latency for subsequent reads but increases write traffic.</em>
                </div>
            </div>

            <!-- Question 27 -->
            <div class="question">
                <h3>27. The Control Unit in the CPU is responsible for:</h3>
                <div class="options">
                    <label><input type="radio" name="q27" value="a"> a) Controls the sequence of instruction execution</label>
                    <label><input type="radio" name="q27" value="b"> b) Performs arithmetic and logical operations</label>
                    <label><input type="radio" name="q27" value="c"> c) Holds instruction addresses temporarily</label>
                    <label><input type="radio" name="q27" value="d"> d) Transfers data between registers and memory</label>
                </div>
                <div class="answer-box" id="answer27" data-correct-answer="a" data-explanation="The control unit fetches instructions, decodes them, and generates control signals to coordinate the datapath, memory, and I/O devices to execute instructions in the correct sequence.">
                    Correct Answer: a<br><br><em>Explanation: The control unit fetches instructions, decodes them, and generates control signals to coordinate the datapath, memory, and I/O devices to execute instructions in the correct sequence.</em>
                </div>
            </div>

            <!-- Question 28 -->
            <div class="question">
                <h3>28. The Datapath in the CPU:</h3>
                <div class="options">
                    <label><input type="radio" name="q28" value="a"> a) Controls the sequence of instruction execution</label>
                    <label><input type="radio" name="q28" value="b"> b) Performs arithmetic and logical operations</label>
                    <label><input type="radio" name="q28" value="c"> c) Holds instruction addresses temporarily</label>
                    <label><input type="radio" name="q28" value="d"> d) Transfers data between registers and memory</label>
                </div>
                <div class="answer-box" id="answer28" data-correct-answer="b" data-explanation="The datapath contains the functional units (ALUs, registers, multiplexers) that perform arithmetic, logical, and data movement operations under control of the control unit.">
                    Correct Answer: b<br><br><em>Explanation: The datapath contains the functional units (ALUs, registers, multiplexers) that perform arithmetic, logical, and data movement operations under control of the control unit.</em>
                </div>
            </div>

            <!-- Question 30 -->
            <div class="question">
                <h3>30. The main purpose of an Operating System (OS) is to:</h3>
                <div class="options">
                    <label><input type="radio" name="q30" value="a"> a) Translate programs into machine language</label>
                    <label><input type="radio" name="q30" value="b"> b) Manage hardware and software resources</label>
                    <label><input type="radio" name="q30" value="c"> c) Increase CPU clock speed</label>
                    <label><input type="radio" name="q30" value="d"> d) Control only the input/output devices</label>
                </div>
                <div class="answer-box" id="answer30" data-correct-answer="b" data-explanation="The OS acts as an intermediary between users/applications and hardware, managing resources like CPU, memory, storage, and I/O devices to provide a stable, efficient execution environment.">
                    Correct Answer: b<br><br><em>Explanation: The OS acts as an intermediary between users/applications and hardware, managing resources like CPU, memory, storage, and I/O devices to provide a stable, efficient execution environment.</em>
                </div>
            </div>

            <!-- Question 31 -->
            <div class="question">
                <h3>31. What is a process in computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q31" value="a"> a) A communication link between systems</label>
                    <label><input type="radio" name="q31" value="b"> b) A hardware unit that performs computations</label>
                    <label><input type="radio" name="q31" value="c"> c) A stored program waiting to be loaded</label>
                    <label><input type="radio" name="q31" value="d"> d) An instance of a program currently being executed</label>
                </div>
                <div class="answer-box" id="answer31" data-correct-answer="d" data-explanation="A process is a program in execution, with its own memory space, register set, and OS resources. Multiple processes can run the same program independently.">
                    Correct Answer: d<br><br><em>Explanation: A process is a program in execution, with its own memory space, register set, and OS resources. Multiple processes can run the same program independently.</em>
                </div>
            </div>

            <!-- Question 32 -->
            <div class="question">
                <h3>32. Which of the following is NOT a component of a process?</h3>
                <div class="options">
                    <label><input type="radio" name="q32" value="a"> a) Executable code</label>
                    <label><input type="radio" name="q32" value="b"> b) Process state</label>
                    <label><input type="radio" name="q32" value="c"> c) Printer driver</label>
                    <label><input type="radio" name="q32" value="d"> d) Security information</label>
                </div>
                <div class="answer-box" id="answer32" data-correct-answer="c" data-explanation="Process components include: code, data, stack, heap, process control block (PCB) containing state, registers, PID, memory info, security permissions, etc. Printer drivers are system-wide, not per-process.">
                    Correct Answer: c<br><br><em>Explanation: Process components include: code, data, stack, heap, process control block (PCB) containing state, registers, PID, memory info, security permissions, etc. Printer drivers are system-wide, not per-process.</em>
                </div>
            </div>

            <!-- Question 33 -->
            <div class="question">
                <h3>33. When a process is ready, it means:</h3>
                <div class="options">
                    <label><input type="radio" name="q33" value="a"> a) It's prepared to run but waiting for CPU time</label>
                    <label><input type="radio" name="q33" value="b"> b) It's currently executing instructions</label>
                    <label><input type="radio" name="q33" value="c"> c) It's paused until an event occurs (like I/O input)</label>
                    <label><input type="radio" name="q33" value="d"> d) It has finished execution</label>
                </div>
                <div class="answer-box" id="answer33" data-correct-answer="a" data-explanation="A ready process has all necessary resources except the CPU. It's waiting in the ready queue for the scheduler to allocate CPU time.">
                    Correct Answer: a<br><br><em>Explanation: A ready process has all necessary resources except the CPU. It's waiting in the ready queue for the scheduler to allocate CPU time.</em>
                </div>
            </div>

            <!-- Question 34 -->
            <div class="question">
                <h3>34. When a process is waiting, it means:</h3>
                <div class="options">
                    <label><input type="radio" name="q34" value="a"> a) It's prepared to run but waiting for CPU time</label>
                    <label><input type="radio" name="q34" value="b"> b) It's currently executing instructions</label>
                    <label><input type="radio" name="q34" value="c"> c) It's paused until an event occurs (like I/O input)</label>
                    <label><input type="radio" name="q34" value="d"> d) It has finished execution</label>
                </div>
                <div class="answer-box" id="answer34" data-correct-answer="c" data-explanation="A waiting (blocked) process cannot proceed until some external event completes, such as I/O completion, message arrival, or resource availability.">
                    Correct Answer: c<br><br><em>Explanation: A waiting (blocked) process cannot proceed until some external event completes, such as I/O completion, message arrival, or resource availability.</em>
                </div>
            </div>

            <!-- Question 35 -->
            <div class="question">
                <h3>35. Which of the following is true about threads?</h3>
                <div class="options">
                    <label><input type="radio" name="q35" value="a"> a) They are independent programs that cannot share memory</label>
                    <label><input type="radio" name="q35" value="b"> b) The smallest unit of execution within a process</label>
                    <label><input type="radio" name="q35" value="c"> c) Always run on separate processors</label>
                    <label><input type="radio" name="q35" value="d"> d) Do not consume any system resources</label>
                </div>
                <div class="answer-box" id="answer35" data-correct-answer="b" data-explanation="Threads are lightweight processes within a process that share the same memory space but have their own stack and register state. They enable concurrent execution within a single program.">
                    Correct Answer: b<br><br><em>Explanation: Threads are lightweight processes within a process that share the same memory space but have their own stack and register state. They enable concurrent execution within a single program.</em>
                </div>
            </div>

            <!-- Question 36 -->
            <div class="question">
                <h3>36. Processes are lighter and faster than threads.</h3>
                <div class="options">
                    <label><input type="radio" name="q36" value="a"> a) True</label>
                    <label><input type="radio" name="q36" value="b"> b) False</label>
                </div>
                <div class="answer-box" id="answer36" data-correct-answer="b" data-explanation="Threads are lighter than processes because they share memory space and OS resources. Thread creation, context switching, and communication are faster than for processes.">
                    Correct Answer: b<br><br><em>Explanation: Threads are lighter than processes because they share memory space and OS resources. Thread creation, context switching, and communication are faster than for processes.</em>
                </div>
            </div>

            <!-- Question 37 -->
            <div class="question">
                <h3>37. A CPU cache is best described as:</h3>
                <div class="options">
                    <label><input type="radio" name="q37" value="a"> a) Small and slow memory that stores used data</label>
                    <label><input type="radio" name="q37" value="b"> b) Part of the hard disk</label>
                    <label><input type="radio" name="q37" value="c"> c) Small and fast memory that stores used data</label>
                    <label><input type="radio" name="q37" value="d"> d) Tool that saves memory</label>
                </div>
                <div class="answer-box" id="answer37" data-correct-answer="c" data-explanation="CPU caches are small, fast SRAM memory located close to the processor that stores frequently accessed data and instructions to reduce latency compared to main memory.">
                    Correct Answer: c<br><br><em>Explanation: CPU caches are small, fast SRAM memory located close to the processor that stores frequently accessed data and instructions to reduce latency compared to main memory.</em>
                </div>
            </div>

            <!-- Question 38 -->
            <div class="question">
                <h3>38. Virtual memory primarily acts as:</h3>
                <div class="options">
                    <label><input type="radio" name="q38" value="a"> a) A cache for main memory (RAM)</label>
                    <label><input type="radio" name="q38" value="b"> b) A cache for CPU registers</label>
                    <label><input type="radio" name="q38" value="c"> c) A cache for secondary storage (disk/SSD)</label>
                    <label><input type="radio" name="q38" value="d"> d) A replacement for the instruction set</label>
                </div>
                <div class="answer-box" id="answer38" data-correct-answer="c" data-explanation="Virtual memory uses disk storage to extend the apparent size of RAM. The OS swaps pages between disk and RAM, treating disk as a slow cache for main memory.">
                    Correct Answer: c<br><br><em>Explanation: Virtual memory uses disk storage to extend the apparent size of RAM. The OS swaps pages between disk and RAM, treating disk as a slow cache for main memory.</em>
                </div>
            </div>

            <!-- Question 39 -->
            <div class="question">
                <h3>39. Registers are large and slow memory units used for long-term data storage.</h3>
                <div class="options">
                    <label><input type="radio" name="q39" value="a"> a) True</label>
                    <label><input type="radio" name="q39" value="b"> b) False</label>
                </div>
                <div class="answer-box" id="answer39" data-correct-answer="b" data-explanation="Registers are the smallest, fastest storage units inside the CPU, used for temporary data during instruction execution. They are volatile and limited in number.">
                    Correct Answer: b<br><br><em>Explanation: Registers are the smallest, fastest storage units inside the CPU, used for temporary data during instruction execution. They are volatile and limited in number.</em>
                </div>
            </div>

            <!-- Question 40 -->
            <div class="question">
                <h3>40. Thread Level Parallelism (TLP) aims to increase processor performance by:</h3>
                <div class="options">
                    <label><input type="radio" name="q40" value="a"> a) Reducing the number of instructions in each program</label>
                    <label><input type="radio" name="q40" value="b"> b) Executing multiple threads concurrently on one or more cores</label>
                    <label><input type="radio" name="q40" value="c"> c) Decreasing memory access time by shrinking caches</label>
                    <label><input type="radio" name="q40" value="d"> d) Executing multiple instructions in parallel within a single program</label>
                </div>
                <div class="answer-box" id="answer40" data-correct-answer="b" data-explanation="TLP exploits parallelism at the thread/process level, either through multithreading on a single core (simultaneous/hyper-threading) or parallel execution across multiple cores.">
                    Correct Answer: b<br><br><em>Explanation: TLP exploits parallelism at the thread/process level, either through multithreading on a single core (simultaneous/hyper-threading) or parallel execution across multiple cores.</em>
                </div>
            </div>

            <!-- Question 41 -->
            <div class="question">
                <h3>41. A processor that supports dynamic multiple issue is often called:</h3>
                <div class="options">
                    <label><input type="radio" name="q41" value="a"> a) Microcoded</label>
                    <label><input type="radio" name="q41" value="b"> b) Superscalar</label>
                    <label><input type="radio" name="q41" value="c"> c) Single-issue</label>
                    <label><input type="radio" name="q41" value="d"> d) Segmented</label>
                </div>
                <div class="answer-box" id="answer41" data-correct-answer="b" data-explanation="Superscalar processors can issue multiple instructions per clock cycle dynamically, using hardware to detect independent instructions and schedule them to multiple execution units.">
                    Correct Answer: b<br><br><em>Explanation: Superscalar processors can issue multiple instructions per clock cycle dynamically, using hardware to detect independent instructions and schedule them to multiple execution units.</em>
                </div>
            </div>

            <!-- Question 42 -->
            <div class="question">
                <h3>42. Which type of multithreading switches threads after each instruction?</h3>
                <div class="options">
                    <label><input type="radio" name="q42" value="a"> a) Fine-Grained Multithreading</label>
                    <label><input type="radio" name="q42" value="b"> b) Coarse-Grained Multithreading</label>
                    <label><input type="radio" name="q42" value="c"> c) Simultaneous Multithreading (SMT)</label>
                    <label><input type="radio" name="q42" value="d"> d) None of the above</label>
                </div>
                <div class="answer-box" id="answer42" data-correct-answer="a" data-explanation="Fine-grained (interleaved) multithreading switches to a different thread each clock cycle, hiding latency by keeping the pipeline full even when one thread stalls.">
                    Correct Answer: a<br><br><em>Explanation: Fine-grained (interleaved) multithreading switches to a different thread each clock cycle, hiding latency by keeping the pipeline full even when one thread stalls.</em>
                </div>
            </div>

            <!-- Question 43 -->
            <div class="question">
                <h3>43. Which type of multithreading switches threads only during long stalls?</h3>
                <div class="options">
                    <label><input type="radio" name="q43" value="a"> a) Fine-Grained Multithreading</label>
                    <label><input type="radio" name="q43" value="b"> b) Coarse-Grained Multithreading</label>
                    <label><input type="radio" name="q43" value="c"> c) Simultaneous Multithreading (SMT)</label>
                    <label><input type="radio" name="q43" value="d"> d) None of the above</label>
                </div>
                <div class="answer-box" id="answer43" data-correct-answer="b" data-explanation="Coarse-grained multithreading switches threads only on significant events like cache misses or pipeline stalls, reducing switching overhead but potentially wasting cycles during short stalls.">
                    Correct Answer: b<br><br><em>Explanation: Coarse-grained multithreading switches threads only on significant events like cache misses or pipeline stalls, reducing switching overhead but potentially wasting cycles during short stalls.</em>
                </div>
            </div>

            <!-- Question 44 -->
            <div class="question">
                <h3>44. Which type of multithreading allows multiple threads to execute instructions at the same time?</h3>
                <div class="options">
                    <label><input type="radio" name="q44" value="a"> a) Fine-Grained Multithreading</label>
                    <label><input type="radio" name="q44" value="b"> b) Coarse-Grained Multithreading</label>
                    <label><input type="radio" name="q44" value="c"> c) Simultaneous Multithreading (SMT)</label>
                    <label><input type="radio" name="q44" value="d"> d) None of the above</label>
                </div>
                <div class="answer-box" id="answer44" data-correct-answer="c" data-explanation="SMT (e.g., Intel Hyper-Threading) allows multiple threads to issue instructions to multiple execution units in the same cycle, truly simultaneous execution within a single core.">
                    Correct Answer: c<br><br><em>Explanation: SMT (e.g., Intel Hyper-Threading) allows multiple threads to issue instructions to multiple execution units in the same cycle, truly simultaneous execution within a single core.</em>
                </div>
            </div>

            <!-- Question 45 -->
            <div class="question">
                <h3>45. Which parallel hardware is usually not visible to the programmer?</h3>
                <div class="options">
                    <label><input type="radio" name="q45" value="a"> a) Multiple issue and pipelining</label>
                    <label><input type="radio" name="q45" value="b"> b) Thread-level parallelism (TLP)</label>
                    <label><input type="radio" name="q45" value="c"> c) Modifying source code</label>
                    <label><input type="radio" name="q45" value="d"> d) Flynn's taxonomy</label>
                </div>
                <div class="answer-box" id="answer45" data-correct-answer="a" data-explanation="Instruction-level parallelism (pipelining, multiple issue) is managed automatically by hardware/compiler and doesn't require explicit programmer control, unlike thread-level parallelism which requires explicit parallel programming.">
                    Correct Answer: a<br><br><em>Explanation: Instruction-level parallelism (pipelining, multiple issue) is managed automatically by hardware/compiler and doesn't require explicit programmer control, unlike thread-level parallelism which requires explicit parallel programming.</em>
                </div>
            </div>

            <!-- Question 46 -->
            <div class="question">
                <h3>46. A basic parallel computer architecture mainly consists of:</h3>
                <div class="options">
                    <label><input type="radio" name="q46" value="a"> a) Memory modules</label>
                    <label><input type="radio" name="q46" value="b"> b) Interconnection network</label>
                    <label><input type="radio" name="q46" value="c"> c) processors (cores)</label>
                    <label><input type="radio" name="q46" value="d"> d) All of above</label>
                </div>
                <div class="answer-box" id="answer46" data-correct-answer="d" data-explanation="Parallel computer architecture comprises processing elements (cores/processors), memory hierarchy (caches, RAM), and interconnection networks that connect processors to each other and to memory.">
                    Correct Answer: d<br><br><em>Explanation: Parallel computer architecture comprises processing elements (cores/processors), memory hierarchy (caches, RAM), and interconnection networks that connect processors to each other and to memory.</em>
                </div>
            </div>

            <!-- Question 47 -->
            <div class="question">
                <h3>47. Modern GPUs often optimize performance using:</h3>
                <div class="options">
                    <label><input type="radio" name="q47" value="a"> a) SISD</label>
                    <label><input type="radio" name="q47" value="b"> b) SIMD</label>
                    <label><input type="radio" name="q47" value="c"> c) MISD</label>
                    <label><input type="radio" name="q47" value="d"> d) MIMD</label>
                </div>
                <div class="answer-box" id="answer47" data-correct-answer="b" data-explanation="GPUs use SIMD (Single Instruction Multiple Data) or SIMT (Single Instruction Multiple Threads) architecture where many cores execute the same instruction on different data elements simultaneously.">
                    Correct Answer: b<br><br><em>Explanation: GPUs use SIMD (Single Instruction Multiple Data) or SIMT (Single Instruction Multiple Threads) architecture where many cores execute the same instruction on different data elements simultaneously.</em>
                </div>
            </div>

            <!-- Question 48 -->
            <div class="question">
                <h3>48. In MIMD systems, processors:</h3>
                <div class="options">
                    <label><input type="radio" name="q48" value="a"> a) Execute the same instruction on different data</label>
                    <label><input type="radio" name="q48" value="b"> b) Execute different instructions on different data</label>
                    <label><input type="radio" name="q48" value="c"> c) Execute the same instruction on the same data</label>
                    <label><input type="radio" name="q48" value="d"> d) Execute one instruction on one data</label>
                </div>
                <div class="answer-box" id="answer48" data-correct-answer="b" data-explanation="MIMD (Multiple Instruction Multiple Data) systems have independent processors that can execute different programs or different parts of the same program on different data, offering maximum flexibility.">
                    Correct Answer: b<br><br><em>Explanation: MIMD (Multiple Instruction Multiple Data) systems have independent processors that can execute different programs or different parts of the same program on different data, offering maximum flexibility.</em>
                </div>
            </div>

            <!-- Question 49 -->
            <div class="question">
                <h3>49. Which of the following best describes MIMD systems?</h3>
                <div class="options">
                    <label><input type="radio" name="q49" value="a"> a) Highly specialized</label>
                    <label><input type="radio" name="q49" value="b"> b) Rare in modern computers</label>
                    <label><input type="radio" name="q49" value="c"> c) Used only in supercomputers</label>
                    <label><input type="radio" name="q49" value="d"> d) The most common modern architecture</label>
                </div>
                <div class="answer-box" id="answer49" data-correct-answer="d" data-explanation="MIMD is the dominant parallel architecture today, encompassing multicore CPUs, clusters, and cloud computing where each core/processor can execute independent tasks.">
                    Correct Answer: d<br><br><em>Explanation: MIMD is the dominant parallel architecture today, encompassing multicore CPUs, clusters, and cloud computing where each core/processor can execute independent tasks.</em>
                </div>
            </div>

            <!-- Question 50 -->
            <div class="question">
                <h3>50. One major drawback of SIMD architecture is:</h3>
                <div class="options">
                    <label><input type="radio" name="q50" value="a"> a) High power consumption</label>
                    <label><input type="radio" name="q50" value="b"> b) Data dependency</label>
                    <label><input type="radio" name="q50" value="c"> c) Some processing units remain idle</label>
                    <label><input type="radio" name="q50" value="d"> d) High memory cost</label>
                </div>
                <div class="answer-box" id="answer50" data-correct-answer="c" data-explanation="In SIMD, all processing units execute the same instruction. If data requires different operations (divergent control flow), some units must remain idle, reducing efficiency.">
                    Correct Answer: c<br><br><em>Explanation: In SIMD, all processing units execute the same instruction. If data requires different operations (divergent control flow), some units must remain idle, reducing efficiency.</em>
                </div>
            </div>

            <!-- Question 51 -->
            <div class="question">
                <h3>51. Which term describes the time it takes for data to travel between processor and memory?</h3>
                <div class="options">
                    <label><input type="radio" name="q51" value="a"> a) Bandwidth</label>
                    <label><input type="radio" name="q51" value="b"> b) Contention</label>
                    <label><input type="radio" name="q51" value="c"> c) Latency</label>
                    <label><input type="radio" name="q51" value="d"> d) Throughput</label>
                </div>
                <div class="answer-box" id="answer51" data-correct-answer="c" data-explanation="Latency is the delay between initiating a memory request and receiving the data. It's critical for performance, especially in parallel systems where processors often wait for data.">
                    Correct Answer: c<br><br><em>Explanation: Latency is the delay between initiating a memory request and receiving the data. It's critical for performance, especially in parallel systems where processors often wait for data.</em>
                </div>
            </div>

            <!-- Question 52 -->
            <div class="question">
                <h3>52. Which term refers to the amount of data that can be transferred between processor and memory in a given time?</h3>
                <div class="options">
                    <label><input type="radio" name="q52" value="a"> a) Latency</label>
                    <label><input type="radio" name="q52" value="b"> b) Bandwidth</label>
                    <label><input type="radio" name="q52" value="c"> c) Contention</label>
                    <label><input type="radio" name="q52" value="d"> d) Cache miss</label>
                </div>
                <div class="answer-box" id="answer52" data-correct-answer="b" data-explanation="Bandwidth measures data transfer rate (e.g., GB/s). High bandwidth allows moving large datasets quickly, important for data-intensive parallel applications.">
                    Correct Answer: b<br><br><em>Explanation: Bandwidth measures data transfer rate (e.g., GB/s). High bandwidth allows moving large datasets quickly, important for data-intensive parallel applications.</em>
                </div>
            </div>

            <!-- Question 53 -->
            <div class="question">
                <h3>53. In a UMA system:</h3>
                <div class="options">
                    <label><input type="radio" name="q53" value="a"> a) Processors access memory at different speeds</label>
                    <label><input type="radio" name="q53" value="b"> b) Processors have private memories only</label>
                    <label><input type="radio" name="q53" value="c"> c) All processors access memory at the same speed</label>
                    <label><input type="radio" name="q53" value="d"> d) Memory cannot be shared</label>
                </div>
                <div class="answer-box" id="answer53" data-correct-answer="c" data-explanation="Uniform Memory Access (UMA) provides symmetric access time to shared memory for all processors, simplifying programming but limiting scalability as processor count increases.">
                    Correct Answer: c<br><br><em>Explanation: Uniform Memory Access (UMA) provides symmetric access time to shared memory for all processors, simplifying programming but limiting scalability as processor count increases.</em>
                </div>
            </div>

            <!-- Question 54 -->
            <div class="question">
                <h3>54. Which statement best describes speculation in processors?</h3>
                <div class="options">
                    <label><input type="radio" name="q54" value="a"> a) Executing instructions only after checking all dependencies</label>
                    <label><input type="radio" name="q54" value="b"> b) Executing instructions in advance based on assumptions</label>
                    <label><input type="radio" name="q54" value="c"> c) Waiting for user input before executing</label>
                    <label><input type="radio" name="q54" value="d"> d) Reducing instruction execution time by half</label>
                </div>
                <div class="answer-box" id="answer54" data-correct-answer="b" data-explanation="Speculative execution predicts program behavior (e.g., branch outcomes) and executes instructions ahead of time. If prediction is correct, performance improves; if wrong, results are discarded.">
                    Correct Answer: b<br><br><em>Explanation: Speculative execution predicts program behavior (e.g., branch outcomes) and executes instructions ahead of time. If prediction is correct, performance improves; if wrong, results are discarded.</em>
                </div>
            </div>

            <!-- Question 55 -->
            <div class="question">
                <h3>55. Which network is a highly connected direct interconnection used in actual systems?</h3>
                <div class="options">
                    <label><input type="radio" name="q55" value="a"> a) Bus network</label>
                    <label><input type="radio" name="q55" value="b"> b) Star network</label>
                    <label><input type="radio" name="q55" value="c"> c) Ring network</label>
                    <label><input type="radio" name="q55" value="d"> d) Hypercube network</label>
                </div>
                <div class="answer-box" id="answer55" data-correct-answer="d" data-explanation="Hypercube (n-cube) networks connect 2^n nodes where each node has n connections. They provide good bisection bandwidth and logarithmic diameter, used in some supercomputers and parallel systems.">
                    Correct Answer: d<br><br><em>Explanation: Hypercube (n-cube) networks connect 2^n nodes where each node has n connections. They provide good bisection bandwidth and logarithmic diameter, used in some supercomputers and parallel systems.</em>
                </div>
            </div>

            <!-- Question 56 -->
            <div class="question">
                <h3>56. In a ring network, which statement is correct?</h3>
                <div class="options">
                    <label><input type="radio" name="q56" value="a"> a) Each node is connected to all other nodes directly.</label>
                    <label><input type="radio" name="q56" value="b"> b) Each node is connected to exactly two other nodes, forming a closed loop.</label>
                    <label><input type="radio" name="q56" value="c"> c) Ring networks have no communication delays.</label>
                    <label><input type="radio" name="q56" value="d"> d) Ring networks are two-dimensional topologies.</label>
                </div>
                <div class="answer-box" id="answer56" data-correct-answer="b" data-explanation="In a ring topology, each node connects to exactly two neighbors, forming a circular path. Data travels around the ring, potentially passing through multiple nodes to reach its destination.">
                    Correct Answer: b<br><br><em>Explanation: In a ring topology, each node connects to exactly two neighbors, forming a circular path. Data travels around the ring, potentially passing through multiple nodes to reach its destination.</em>
                </div>
            </div>

            <!-- Question 57 -->
            <div class="question">
                <h3>57. Which characteristic describes a toroidal mesh network?</h3>
                <div class="options">
                    <label><input type="radio" name="q57" value="a"> a) Nodes are arranged in a line with two end nodes connected.</label>
                    <label><input type="radio" name="q57" value="b"> b) Nodes are arranged in a 2D grid with wrap-around connections at the edges.</label>
                    <label><input type="radio" name="q57" value="c"> c) Each node is connected to only one neighbor.</label>
                    <label><input type="radio" name="q57" value="d"> d) It is the same as a star network topology.</label>
                </div>
                <div class="answer-box" id="answer57" data-correct-answer="b" data-explanation="A toroidal mesh is a 2D grid where nodes on opposite edges are connected, forming a torus shape. This reduces network diameter and improves load balancing compared to a simple mesh.">
                    Correct Answer: b<br><br><em>Explanation: A toroidal mesh is a 2D grid where nodes on opposite edges are connected, forming a torus shape. This reduces network diameter and improves load balancing compared to a simple mesh.</em>
                </div>
            </div>

            <!-- Question 58 -->
            <div class="question">
                <h3>58. What is the difference between temporal locality and spatial locality in memory access?</h3>
                <div class="options">
                    <label><input type="radio" name="q58" value="a"> a) Temporal locality means accessing data near recently accessed data; spatial locality means accessing the same data repeatedly.</label>
                    <label><input type="radio" name="q58" value="b"> b) Temporal locality means accessing the same data repeatedly; spatial locality means accessing data near recently accessed data.</label>
                    <label><input type="radio" name="q58" value="c"> c) Temporal locality refers to memory allocation patterns; spatial locality refers to processor speed.</label>
                    <label><input type="radio" name="q58" value="d"> d) Temporal locality applies only to caches; spatial locality applies only to main memory.</label>
                </div>
                <div class="answer-box" id="answer58" data-correct-answer="b" data-explanation="Temporal locality: recently accessed data is likely to be accessed again soon. Spatial locality: data near recently accessed data is likely to be accessed soon. Both principles guide cache design.">
                    Correct Answer: b<br><br><em>Explanation: Temporal locality: recently accessed data is likely to be accessed again soon. Spatial locality: data near recently accessed data is likely to be accessed soon. Both principles guide cache design.</em>
                </div>
            </div>

            <!-- Question 59 -->
            <div class="question">
                <h3>59. Which cache level is smallest and fastest?</h3>
                <div class="options">
                    <label><input type="radio" name="q59" value="a"> a) L3</label>
                    <label><input type="radio" name="q59" value="b"> b) L2</label>
                    <label><input type="radio" name="q59" value="c"> c) L1</label>
                    <label><input type="radio" name="q59" value="d"> d) All of above</label>
                </div>
                <div class="answer-box" id="answer59" data-correct-answer="c" data-explanation="L1 cache is closest to the CPU core, smallest (typically 32-64KB), and fastest (1-4 cycle latency). L2 is larger/slower, L3 is largest/slowest and often shared among cores.">
                    Correct Answer: c<br><br><em>Explanation: L1 cache is closest to the CPU core, smallest (typically 32-64KB), and fastest (1-4 cycle latency). L2 is larger/slower, L3 is largest/slowest and often shared among cores.</em>
                </div>
            </div>

            <!-- Question 60 -->
            <div class="question">
                <h3>60. A cache miss occurs when:</h3>
                <div class="options">
                    <label><input type="radio" name="q60" value="a"> a) Data is read from the cache successfully</label>
                    <label><input type="radio" name="q60" value="b"> b) The cache is full but the data is present</label>
                    <label><input type="radio" name="q60" value="c"> c) The requested data is not found in the cache</label>
                    <label><input type="radio" name="q60" value="d"> d) The CPU executes instructions from multiple threads</label>
                </div>
                <div class="answer-box" id="answer60" data-correct-answer="c" data-explanation="A cache miss requires fetching data from a slower level (higher cache or main memory), causing significant delay. Cache hit ratio is critical for performance.">
                    Correct Answer: c<br><br><em>Explanation: A cache miss requires fetching data from a slower level (higher cache or main memory), causing significant delay. Cache hit ratio is critical for performance.</em>
                </div>
            </div>

            <!-- Question 61 -->
            <div class="question">
                <h3>61. What is the primary purpose of a write-through cache?</h3>
                <div class="options">
                    <label><input type="radio" name="q61" value="a"> a) To immediately write modifications to the main memory</label>
                    <label><input type="radio" name="q61" value="b"> b) To delay writing modifications to the main memory until necessary</label>
                    <label><input type="radio" name="q61" value="c"> c) To prevent any modifications from being written to the main memory</label>
                    <label><input type="radio" name="q61" value="d"> d) To write modifications only on system shutdown</label>
                </div>
                <div class="answer-box" id="answer61" data-correct-answer="a" data-explanation="Write-through caches update both cache and main memory on every write, ensuring memory consistency but generating more memory traffic. Simpler but slower than write-back.">
                    Correct Answer: a<br><br><em>Explanation: Write-through caches update both cache and main memory on every write, ensuring memory consistency but generating more memory traffic. Simpler but slower than write-back.</em>
                </div>
            </div>

            <!-- Question 62 -->
            <div class="question">
                <h3>62. What is the difference between task parallelism and data parallelism?</h3>
                <div class="options">
                    <label><input type="radio" name="q62" value="a"> a) Task parallelism executes the same operation on multiple data items; data parallelism executes distinct operations concurrently.</label>
                    <label><input type="radio" name="q62" value="b"> b) Task parallelism executes distinct operations concurrently; data parallelism executes the same operation on multiple data items.</label>
                    <label><input type="radio" name="q62" value="c"> c) Task parallelism requires only one processor; data parallelism requires multiple processors.</label>
                    <label><input type="radio" name="q62" value="d"> d) Task parallelism is used for vector operations; data parallelism is used for sequential code.</label>
                </div>
                <div class="answer-box" id="answer62" data-correct-answer="b" data-explanation="Task parallelism: different threads perform different tasks on same/different data. Data parallelism: same task applied to different data subsets. Most parallel programs use both.">
                    Correct Answer: b<br><br><em>Explanation: Task parallelism: different threads perform different tasks on same/different data. Data parallelism: same task applied to different data subsets. Most parallel programs use both.</em>
                </div>
            </div>

            <!-- Question 64 -->
            <div class="question">
                <h3>64. What is the main objective of parallelizing a sequential program?</h3>
                <div class="options">
                    <label><input type="radio" name="q64" value="a"> a) Reducing the number of lines in the code</label>
                    <label><input type="radio" name="q64" value="b"> b) Increasing the number of processors used</label>
                    <label><input type="radio" name="q64" value="c"> c) Executing different parts of the program simultaneously</label>
                    <label><input type="radio" name="q64" value="d"> d) Decreasing the size of the array</label>
                </div>
                <div class="answer-box" id="answer64" data-correct-answer="c" data-explanation="Parallelization aims to divide computational work among multiple processing elements to reduce execution time (speedup) or solve larger problems (scalability) by exploiting concurrency.">
                    Correct Answer: c<br><br><em>Explanation: Parallelization aims to divide computational work among multiple processing elements to reduce execution time (speedup) or solve larger problems (scalability) by exploiting concurrency.</em>
                </div>
            </div>

            <!-- Question 65 -->
            <div class="question">
                <h3>65. What is data dependence in parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q65" value="a"> a) When multiple instructions are executed simultaneously</label>
                    <label><input type="radio" name="q65" value="b"> b) When an instruction depends on the execution of a previous instruction</label>
                    <label><input type="radio" name="q65" value="c"> c) When tasks are randomly assigned to processors.</label>
                    <label><input type="radio" name="q65" value="d"> d) When all variables are stored in shared memory.</label>
                </div>
                <div class="answer-box" id="answer65" data-correct-answer="b" data-explanation="Data dependence occurs when one computation requires the result of another, creating a serial constraint that limits parallelism. Identifying and managing dependencies is crucial for parallelization.">
                    Correct Answer: b<br><br><em>Explanation: Data dependence occurs when one computation requires the result of another, creating a serial constraint that limits parallelism. Identifying and managing dependencies is crucial for parallelization.</em>
                </div>
            </div>

            <!-- Question 66 -->
            <div class="question">
                <h3>66. In a parallel program, data independence allows for:</h3>
                <div class="options">
                    <label><input type="radio" name="q66" value="a"> a) Slower execution</label>
                    <label><input type="radio" name="q66" value="b"> b) Correct parallel execution</label>
                    <label><input type="radio" name="q66" value="c"> c) Synchronization between threads</label>
                    <label><input type="radio" name="q66" value="d"> d) Increased data dependency</label>
                </div>
                <div class="answer-box" id="answer66" data-correct-answer="b" data-explanation="Independent computations can execute concurrently without synchronization, enabling efficient parallel execution. The more independence, the more parallelism can be exploited.">
                    Correct Answer: b<br><br><em>Explanation: Independent computations can execute concurrently without synchronization, enabling efficient parallel execution. The more independence, the more parallelism can be exploited.</em>
                </div>
            </div>

            <!-- Question 67 -->
            <div class="question">
                <h3>67. What is one main effect of data dependence in parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q67" value="a"> a) It increases the speed of execution.</label>
                    <label><input type="radio" name="q67" value="b"> b) It allows more processors to work at the same time.</label>
                    <label><input type="radio" name="q67" value="c"> c) It prevents some instructions from running in parallel.</label>
                    <label><input type="radio" name="q67" value="d"> d) It removes the need for synchronization.</label>
                </div>
                <div class="answer-box" id="answer67" data-correct-answer="c" data-explanation="Dependencies create ordering constraints (happen-before relationships) that serialize execution, limiting the available parallelism and potentially causing threads to wait for data.">
                    Correct Answer: c<br><br><em>Explanation: Dependencies create ordering constraints (happen-before relationships) that serialize execution, limiting the available parallelism and potentially causing threads to wait for data.</em>
                </div>
            </div>

            <!-- Question 68 -->
            <div class="question">
                <h3>68. Consider the following code snippet:</h3>
                <div class="code-block">
<pre>int x = 0
int y = 5
x = 3;
y = y + x;</pre>
                </div>
                <p>Which statement is true regarding parallel execution?</p>
                <div class="options">
                    <label><input type="radio" name="q68" value="a"> a) x and y are independent and can be executed in parallel</label>
                    <label><input type="radio" name="q68" value="b"> b) x and y are independent</label>
                    <label><input type="radio" name="q68" value="c"> c) y's calculation depends on x, preventing parallel execution</label>
                    <label><input type="radio" name="q68" value="d"> d) The code can be parallelized without any issues</label>
                </div>
                <div class="answer-box" id="answer68" data-correct-answer="c" data-explanation="Statement 'y = y + x' reads x after x is written in 'x = 3', creating a true (flow) dependence (RAW). This serializes the two statements‚Äîx must be computed before y can be updated.">
                    Correct Answer: c<br><br><em>Explanation: Statement 'y = y + x' reads x after x is written in 'x = 3', creating a true (flow) dependence (RAW). This serializes the two statements‚Äîx must be computed before y can be updated.</em>
                </div>
            </div>

            <!-- Question 69 -->
            <div class="question">
                <h3>69. Consider the following code snippet:</h3>
                <div class="code-block">
<pre>int x = 0
int y = 5
x = 3;
y = y + 5;</pre>
                </div>
                <p>Which statement is true regarding parallel execution?</p>
                <div class="options">
                    <label><input type="radio" name="q69" value="a"> a) x and y are independent and can be executed in parallel</label>
                    <label><input type="radio" name="q69" value="b"> b) x depends on y, preventing parallel execution</label>
                    <label><input type="radio" name="q69" value="c"> c) y depends on x, preventing parallel execution</label>
                    <label><input type="radio" name="q69" value="d"> d) The code cannot be executed in parallel</label>
                </div>
                <div class="answer-box" id="answer69" data-correct-answer="a" data-explanation="The two assignments modify different variables (x and y) and neither reads the other's output. They are independent and can execute in any order, including concurrently.">
                    Correct Answer: a<br><br><em>Explanation: The two assignments modify different variables (x and y) and neither reads the other's output. They are independent and can execute in any order, including concurrently.</em>
                </div>
            </div>

            <!-- Question 70 -->
            <div class="question">
                <h3>70. What is data independence in programming?</h3>
                <div class="options">
                    <label><input type="radio" name="q70" value="a"> a) Data is automatically synchronized between instructions</label>
                    <label><input type="radio" name="q70" value="b"> b) Variables must be declared before use</label>
                    <label><input type="radio" name="q70" value="c"> c) All instructions must execute sequentially</label>
                    <label><input type="radio" name="q70" value="d"> d) An instruction can execute without depending on previous instructions</label>
                </div>
                <div class="answer-box" id="answer70" data-correct-answer="d" data-explanation="Data independence means computations don't share data or have well-defined, non-conflicting access patterns, allowing them to proceed concurrently without synchronization or communication.">
                    Correct Answer: d<br><br><em>Explanation: Data independence means computations don't share data or have well-defined, non-conflicting access patterns, allowing them to proceed concurrently without synchronization or communication.</em>
                </div>
            </div>

            <!-- Question 71 -->
            <div class="question">
                <h3>71. Consider the following code snippet:</h3>
                <div class="code-block">
<pre>int sum = 0;
for(int i = 0; i < size; i++) {
    sum += array[i];
}</pre>
                </div>
                <p>Why does this loop have data dependence and cannot be safely executed in parallel?</p>
                <div class="options">
                    <label><input type="radio" name="q71" value="a"> a) Because array[i] elements might occasionally have the same value, which creates data dependence.</label>
                    <label><input type="radio" name="q71" value="b"> b) Because each iteration modifies sum, and the next iteration needs the updated value.</label>
                    <label><input type="radio" name="q71" value="c"> c) Because the loop index i changes in each iteration, causing a data dependence.</label>
                    <label><input type="radio" name="q71" value="d"> d) Because any loop with arithmetic operations inherently has data dependence.</label>
                </div>
                <div class="answer-box" id="answer71" data-correct-answer="b" data-explanation="The reduction variable 'sum' creates a loop-carried dependence: iteration i reads sum written by iteration i-1 (or earlier). This is a true dependence (RAW) that serializes the loop.">
                    Correct Answer: b<br><br><em>Explanation: The reduction variable 'sum' creates a loop-carried dependence: iteration i reads sum written by iteration i-1 (or earlier). This is a true dependence (RAW) that serializes the loop.</em>
                </div>
            </div>

            <!-- Question 72 -->
            <div class="question">
                <h3>72. Why do we use middleSum arrays in a multithreaded sum of an array?</h3>
                <div class="options">
                    <label><input type="radio" name="q72" value="a"> a) To make each thread depend on the global sum</label>
                    <label><input type="radio" name="q72" value="b"> b) To remove data dependencies between threads</label>
                    <label><input type="radio" name="q72" value="c"> c) To slow down the computation</label>
                    <label><input type="radio" name="q72" value="d"> d) To temporarily store the array elements</label>
                </div>
                <div class="answer-box" id="answer72" data-correct-answer="b" data-explanation="Each thread computes a partial sum into its own middleSum element, eliminating write conflicts. After all threads finish, the partial sums are combined sequentially, reducing synchronization overhead.">
                    Correct Answer: b<br><br><em>Explanation: Each thread computes a partial sum into its own middleSum element, eliminating write conflicts. After all threads finish, the partial sums are combined sequentially, reducing synchronization overhead.</em>
                </div>
            </div>

            <!-- Question 73 -->
            <div class="question">
                <h3>73. How does load balancing improve the performance of parallel programs?</h3>
                <div class="options">
                    <label><input type="radio" name="q73" value="a"> a) By ensuring threads access memory equally</label>
                    <label><input type="radio" name="q73" value="b"> b) By assigning equal work to each processor to avoid idle time</label>
                    <label><input type="radio" name="q73" value="c"> c) By increasing the number of threads</label>
                    <label><input type="radio" name="q73" value="d"> d) By preventing false sharing</label>
                </div>
                <div class="answer-box" id="answer73" data-correct-answer="b" data-explanation="Good load balancing ensures all processors finish their work at similar times, minimizing idle periods where fast processors wait for slower ones. This maximizes utilization and speedup.">
                    Correct Answer: b<br><br><em>Explanation: Good load balancing ensures all processors finish their work at similar times, minimizing idle periods where fast processors wait for slower ones. This maximizes utilization and speedup.</em>
                </div>
            </div>

<div class="question">
    <h3>74. Why does adding more threads not always make a parallel program faster?</h3>
    
    <div class="code-block" style="text-align: center; border: 1px solid var(--border-color);">
        <img src="image_0c4e7f.png" alt="Time on 2-core Processor Graph" style="max-width: 100%; height: auto; border-radius: 8px;">
        <p style="font-size: 0.9rem; color: var(--text-color); margin-top: 10px; opacity: 0.8;">
            Figure: Performance analysis on a 2-core processor 
        </p>
    </div>

    <div class="options">
        <label><input type="radio" name="q74" value="a"> a) Threads always finish at the same speed </label>
        <label><input type="radio" name="q74" value="b"> b) False sharing and scheduling overhead can reduce performance </label>
        <label><input type="radio" name="q74" value="c"> c) More threads always increase correctness </label>
        <label><input type="radio" name="q74" value="d"> d) The program will crash </label>
    </div>
    <div class="answer-box" id="answer74" data-correct-answer="b" data-explanation="As shown in the graph, increasing threads beyond the core count (from 2 to 4 threads on 2 cores) can actually increase execution time due to scheduling overhead, context switching, and resource contention like false sharing.">
        Correct Answer: b <br><br><em>Explanation: As shown in the graph, increasing threads beyond the core count (from 2 to 4 threads on 2 cores) can actually increase execution time due to scheduling overhead, context switching, and resource contention like false sharing.</em>
    </div>
</div>

            <!-- Question 75 -->
            <div class="question">
                <h3>75. What is a characteristic of a well-balanced parallel program?</h3>
                <div class="options">
                    <label><input type="radio" name="q75" value="a"> a) Threads execute tasks without synchronization</label>
                    <label><input type="radio" name="q75" value="b"> b) All processors are kept equally busy during the program execution</label>
                    <label><input type="radio" name="q75" value="c"> c) Make all threads work independently on different problems</label>
                    <label><input type="radio" name="q75" value="d"> d) Memory usage is minimized</label>
                </div>
                <div class="answer-box" id="answer75" data-correct-answer="b" data-explanation="A well-balanced program distributes work evenly so that all processors complete their assigned tasks at approximately the same time, maximizing parallel efficiency and minimizing idle time.">
                    Correct Answer: b<br><br><em>Explanation: A well-balanced program distributes work evenly so that all processors complete their assigned tasks at approximately the same time, maximizing parallel efficiency and minimizing idle time.</em>
                </div>
            </div>

            <!-- Question 76 -->
            <div class="question">
                <h3>76. What is the purpose of the WaitForAllThreads() function in parallel programming?</h3>
                <div class="options">
                    <label><input type="radio" name="q76" value="a"> a) To ensure one thread finishes before others</label>
                    <label><input type="radio" name="q76" value="b"> b) To allow threads to execute independently</label>
                    <label><input type="radio" name="q76" value="c"> c) To ensure all threads have finished execution before continuing</label>
                    <label><input type="radio" name="q76" value="d"> d) To optimize memory usage</label>
                </div>
                <div class="answer-box" id="answer76" data-correct-answer="c" data-explanation="This is a barrier synchronization that makes the master thread (or all threads) wait until all worker threads complete their tasks, ensuring correctness before proceeding to the next phase.">
                    Correct Answer: c<br><br><em>Explanation: This is a barrier synchronization that makes the master thread (or all threads) wait until all worker threads complete their tasks, ensuring correctness before proceeding to the next phase.</em>
                </div>
            </div>

            <!-- Question 77 -->
            <div class="question">
                <h3>77. What is SPMD (Single Program Multiple Data) model?</h3>
                <div class="options">
                    <label><input type="radio" name="q77" value="a"> a) Multiple identical programs execute on different processors using the same data set.</label>
                    <label><input type="radio" name="q77" value="b"> b) A single program executes on multiple processors using different data and conditional branches.</label>
                    <label><input type="radio" name="q77" value="c"> c) A single program executes sequentially while sharing data between processors.</label>
                    <label><input type="radio" name="q77" value="d"> d) Different programs are compiled into one executable and executed on a single processor.</label>
                </div>
                <div class="answer-box" id="answer77" data-correct-answer="b" data-explanation="In SPMD, all processors run the same program code but operate on different data partitions. Processors may take different control paths based on their ID or data, enabling both data and task parallelism.">
                    Correct Answer: b<br><br><em>Explanation: In SPMD, all processors run the same program code but operate on different data partitions. Processors may take different control paths based on their ID or data, enabling both data and task parallelism.</em>
                </div>
            </div>

            <!-- Question 78 -->
            <div class="question">
                <h3>78. What is the main difference between dynamic threads and static threads?</h3>
                <div class="options">
                    <label><input type="radio" name="q78" value="a"> a) Dynamic threads are permanent, static threads terminate after work</label>
                    <label><input type="radio" name="q78" value="b"> b) Dynamic threads created and terminated for each task, static threads stay alive until cleanup</label>
                    <label><input type="radio" name="q78" value="c"> c) Dynamic threads cannot share memory, static threads can</label>
                    <label><input type="radio" name="q78" value="d"> d) Static threads created and terminated for each task, dynamic threads stay alive until cleanup</label>
                </div>
                <div class="answer-box" id="answer78" data-correct-answer="b" data-explanation="Static threading creates threads once at program start and reuses them for multiple tasks (thread pool). Dynamic threading creates/destroys threads per task, higher overhead but more flexible.">
                    Correct Answer: b<br><br><em>Explanation: Static threading creates threads once at program start and reuses them for multiple tasks (thread pool). Dynamic threading creates/destroys threads per task, higher overhead but more flexible.</em>
                </div>
            </div>

            <!-- Question 79 -->
            <div class="question">
                <h3>79. What is the main focus of SPMD (Single Program Multiple Data) programs?</h3>
                <div class="options">
                    <label><input type="radio" name="q79" value="a"> a) Communication between processes</label>
                    <label><input type="radio" name="q79" value="b"> b) Shared memory management</label>
                    <label><input type="radio" name="q79" value="c"> c) Implementing both task parallelism and data parallelism</label>
                    <label><input type="radio" name="q79" value="d"> d) Synchronizing threads</label>
                </div>
                <div class="answer-box" id="answer79" data-correct-answer="c" data-explanation="SPMD programs can express both data parallelism (same operation on different data) and task parallelism (different code paths based on processor ID or data characteristics) within a unified model.">
                    Correct Answer: c<br><br><em>Explanation: SPMD programs can express both data parallelism (same operation on different data) and task parallelism (different code paths based on processor ID or data characteristics) within a unified model.</em>
                </div>
            </div>

            <!-- Question 80 -->
            <div class="question">
                <h3>80. In shared memory systems, what does 'nondeterminism' refer to?</h3>
                <div class="options">
                    <label><input type="radio" name="q80" value="a"> a) The system's ability to synchronize threads</label>
                    <label><input type="radio" name="q80" value="b"> b) The result can be different each time threads run.</label>
                    <label><input type="radio" name="q80" value="c"> c) The elimination of race conditions</label>
                    <label><input type="radio" name="q80" value="d"> d) A system with guaranteed sequential execution</label>
                </div>
                <div class="answer-box" id="answer80" data-correct-answer="b" data-explanation="Nondeterminism arises from unpredictable thread scheduling and memory access interleaving in parallel programs without proper synchronization, potentially producing different results in different runs.">
                    Correct Answer: b<br><br><em>Explanation: Nondeterminism arises from unpredictable thread scheduling and memory access interleaving in parallel programs without proper synchronization, potentially producing different results in different runs.</em>
                </div>
            </div>

            <!-- Question 81 -->
            <div class="question">
                <h3>81. Which of the following is an alternative to mutexes for synchronizing threads?</h3>
                <div class="options">
                    <label><input type="radio" name="q81" value="a"> a) Busy-waiting</label>
                    <label><input type="radio" name="q81" value="b"> b) Shared memory</label>
                    <label><input type="radio" name="q81" value="c"> c) Thread forking</label>
                    <label><input type="radio" name="q81" value="d"> d) Memory padding</label>
                </div>
                <div class="answer-box" id="answer81" data-correct-answer="a" data-explanation="Busy-waiting (spin locks) repeatedly checks a condition in a loop. Other alternatives include semaphores, condition variables, barriers, atomic operations, lock-free/wait-free algorithms, and transactional memory.">
                    Correct Answer: a<br><br><em>Explanation: Busy-waiting (spin locks) repeatedly checks a condition in a loop. Other alternatives include semaphores, condition variables, barriers, atomic operations, lock-free/wait-free algorithms, and transactional memory.</em>
                </div>
            </div>

            <!-- Question 82 -->
            <div class="question">
                <h3>82. What is the primary function of the message-passing interface (MPI)?</h3>
                <div class="options">
                    <label><input type="radio" name="q82" value="a"> a) To synchronize threads within a single process</label>
                    <label><input type="radio" name="q82" value="b"> b) To communicate between processes in a distributed memory system</label>
                    <label><input type="radio" name="q82" value="c"> c) To manage shared memory in parallel programs</label>
                    <label><input type="radio" name="q82" value="d"> d) To communicate between processes in a shared memory system</label>
                </div>
                <div class="answer-box" id="answer82" data-correct-answer="b" data-explanation="MPI is a standardized API for point-to-point and collective communication between processes running on different nodes in a cluster or distributed memory system.">
                    Correct Answer: b<br><br><em>Explanation: MPI is a standardized API for point-to-point and collective communication between processes running on different nodes in a cluster or distributed memory system.</em>
                </div>
            </div>

            <!-- Question 83 -->
            <div class="question">
                <h3>83. In parallel programs, what is typically used to access input and output (I/O)?</h3>
                <div class="options">
                    <label><input type="radio" name="q83" value="a"> a) All threads/processes access stdin and stdout equally</label>
                    <label><input type="radio" name="q83" value="b"> b) Only the master thread or process accesses stdin</label>
                    <label><input type="radio" name="q83" value="c"> c) I/O is never performed in parallel programs</label>
                    <label><input type="radio" name="q83" value="d"> d) I/O is handled by multiple threads writing to stdout</label>
                </div>
                <div class="answer-box" id="answer83" data-correct-answer="b" data-explanation="To avoid chaos, typically one thread (master/rank 0) reads input and distributes data. Output is often gathered to master for printing, or threads write to separate files.">
                    Correct Answer: b<br><br><em>Explanation: To avoid chaos, typically one thread (master/rank 0) reads input and distributes data. Output is often gathered to master for printing, or threads write to separate files.</em>
                </div>
            </div>

            <!-- Question 84 -->
            <div class="question">
                <h3>84. What is the primary goal of measuring performance in parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q84" value="a"> a) To calculate the total execution time of all threads</label>
                    <label><input type="radio" name="q84" value="b"> b) To evaluate the overheads introduced by parallelization</label>
                    <label><input type="radio" name="q84" value="c"> c) To ensure that all threads execute simultaneously without delays</label>
                    <label><input type="radio" name="q84" value="d"> d) To determine the speedup and efficiency of parallel execution</label>
                </div>
                <div class="answer-box" id="answer84" data-correct-answer="d" data-explanation="Performance metrics like speedup, efficiency, scalability, and overhead help evaluate how well parallelism is exploited, identify bottlenecks, and guide optimization efforts.">
                    Correct Answer: d<br><br><em>Explanation: Performance metrics like speedup, efficiency, scalability, and overhead help evaluate how well parallelism is exploited, identify bottlenecks, and guide optimization efforts.</em>
                </div>
            </div>

            <!-- Question 85 -->
            <div class="question">
                <h3>85. A program takes 10 seconds on 1 processor. On 2 processors, it runs in 5 seconds. What does this indicate?</h3>
                <div class="options">
                    <label><input type="radio" name="q85" value="a"> a) The program is slower than expected</label>
                    <label><input type="radio" name="q85" value="b"> b) The program achieves perfect linear speedup</label>
                    <label><input type="radio" name="q85" value="c"> c) The program has overheads slowing it down</label>
                    <label><input type="radio" name="q85" value="d"> d) The program cannot scale to more processors</label>
                </div>
                <div class="answer-box" id="answer85" data-correct-answer="b" data-explanation="Linear speedup: T_parallel = T_serial / p. Here, 5 = 10 / 2, ideal scaling. This rarely happens in practice due to parallel overheads, communication, and serial portions.">
                    Correct Answer: b<br><br><em>Explanation: Linear speedup: T_parallel = T_serial / p. Here, 5 = 10 / 2, ideal scaling. This rarely happens in practice due to parallel overheads, communication, and serial portions.</em>
                </div>
            </div>

            <!-- Question 86 -->
            <div class="question">
                <h3>86. A program takes 10 seconds on 1 processor. On 2 processors, it runs in 6 seconds. What does this indicate?</h3>
                <div class="options">
                    <label><input type="radio" name="q86" value="a"> a) The program achieves perfect linear speedup</label>
                    <label><input type="radio" name="q86" value="b"> b) The program is slower than serial execution</label>
                    <label><input type="radio" name="q86" value="c"> c) The program has overheads slowing it down</label>
                    <label><input type="radio" name="q86" value="d"> d) The program cannot run on more than 2 processors</label>
                </div>
                <div class="answer-box" id="answer86" data-correct-answer="c" data-explanation="Speedup = 10/6 ‚âà 1.67 < 2. The extra 1 second (6 vs ideal 5) represents parallel overhead: thread creation, synchronization, communication, load imbalance, etc.">
                    Correct Answer: c<br><br><em>Explanation: Speedup = 10/6 ‚âà 1.67 < 2. The extra 1 second (6 vs ideal 5) represents parallel overhead: thread creation, synchronization, communication, load imbalance, etc.</em>
                </div>
            </div>

            <!-- Question 87 -->
            <div class="question">
                <h3>87. In a parallel program, what is 'overhead'?</h3>
                <div class="options">
                    <label><input type="radio" name="q87" value="a"> a) The extra computation required to solve the problem sequentially.</label>
                    <label><input type="radio" name="q87" value="b"> b) The extra work, time, or resources required to manage parallelism</label>
                    <label><input type="radio" name="q87" value="c"> c) The total number of processors used in the program.</label>
                    <label><input type="radio" name="q87" value="d"> d) The memory required to store input data only.</label>
                </div>
                <div class="answer-box" id="answer87" data-correct-answer="b" data-explanation="Parallel overhead includes thread/process management, synchronization, communication, load balancing, and extra computation not present in the sequential version.">
                    Correct Answer: b<br><br><em>Explanation: Parallel overhead includes thread/process management, synchronization, communication, load balancing, and extra computation not present in the sequential version.</em>
                </div>
            </div>

            <!-- Question 88 -->
            <div class="question">
                <h3>88. Which type of speedup occurs when the speedup S is less than the number of processors p?</h3>
                <div class="options">
                    <label><input type="radio" name="q88" value="a"> a) Super-linear speedup</label>
                    <label><input type="radio" name="q88" value="b"> b) Linear speedup</label>
                    <label><input type="radio" name="q88" value="c"> c) Sub-linear speedup</label>
                    <label><input type="radio" name="q88" value="d"> d) No speedup</label>
                </div>
                <div class="answer-box" id="answer88" data-correct-answer="c" data-explanation="Sub-linear speedup (S < p) is typical due to parallel overheads, serial sections (Amdahl's Law), communication costs, and resource contention.">
                    Correct Answer: c<br><br><em>Explanation: Sub-linear speedup (S < p) is typical due to parallel overheads, serial sections (Amdahl's Law), communication costs, and resource contention.</em>
                </div>
            </div>

            <!-- Question 89 -->
            <div class="question">
                <h3>89. Which type of speedup occurs when the speedup S is equal to the number of processors p?</h3>
                <div class="options">
                    <label><input type="radio" name="q89" value="a"> a) Super-linear speedup</label>
                    <label><input type="radio" name="q89" value="b"> b) Linear speedup</label>
                    <label><input type="radio" name="q89" value="c"> c) Sub-linear speedup</label>
                    <label><input type="radio" name="q89" value="d"> d) No speedup</label>
                </div>
                <div class="answer-box" id="answer89" data-correct-answer="b" data-explanation="Linear speedup (S = p) is ideal but rarely achieved in practice. It would mean perfect parallelization with zero overhead, which is theoretically possible for embarrassingly parallel problems.">
                    Correct Answer: b<br><br><em>Explanation: Linear speedup (S = p) is ideal but rarely achieved in practice. It would mean perfect parallelization with zero overhead, which is theoretically possible for embarrassingly parallel problems.</em>
                </div>
            </div>

            <!-- Question 90 -->
            <div class="question">
                <h3>90. Which type of speedup occurs when the speedup S is greater than the number of processors p?</h3>
                <div class="options">
                    <label><input type="radio" name="q90" value="a"> a) Super-linear speedup</label>
                    <label><input type="radio" name="q90" value="b"> b) Linear speedup</label>
                    <label><input type="radio" name="q90" value="c"> c) Sub-linear speedup</label>
                    <label><input type="radio" name="q90" value="d"> d) No speedup</label>
                </div>
                <div class="answer-box" id="answer90" data-correct-answer="a" data-explanation="Super-linear speedup (S > p) can occur due to cache effects (aggregate cache size increases with more processors), algorithmic advantages, or reduced paging, but is uncommon.">
                    Correct Answer: a<br><br><em>Explanation: Super-linear speedup (S > p) can occur due to cache effects (aggregate cache size increases with more processors), algorithmic advantages, or reduced paging, but is uncommon.</em>
                </div>
            </div>

            <!-- Question 91 -->
            <div class="question">
                <h3>91. What is the formula for calculating speedup (S) in parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q91" value="a"> a) S = T_serial / T_parallel</label>
                    <label><input type="radio" name="q91" value="b"> b) S = T_parallel / T_serial</label>
                    <label><input type="radio" name="q91" value="c"> c) S = T_serial / P</label>
                    <label><input type="radio" name="q91" value="d"> d) S = P √ó T_serial</label>
                </div>
                <div class="answer-box" id="answer91" data-correct-answer="a" data-explanation="Speedup compares sequential execution time to parallel execution time: S = T_seq / T_par. Values >1 indicate improvement; ideal is S = p (number of processors).">
                    Correct Answer: a<br><br><em>Explanation: Speedup compares sequential execution time to parallel execution time: S = T_seq / T_par. Values >1 indicate improvement; ideal is S = p (number of processors).</em>
                </div>
            </div>

            <!-- Question 92 -->
            <div class="question">
                <h3>92. An array sum program has the following execution times:</h3>
                <ul>
                    <li>Sequential program: T_s = 0.52 sec</li>
                    <li>Parallel program with 1 thread: T_1 = 0.86 sec</li>
                    <li>Parallel program with 2 threads: T_2 = 0.45 sec</li>
                </ul>
                <p>Which of the following statements is correct?</p>
                <div class="options">
                    <label><input type="radio" name="q92" value="a"> a) Absolute speedup = T_s / T_1 = 0.86, relative speedup = T_2 / T_1 = 0.52</label>
                    <label><input type="radio" name="q92" value="b"> b) Absolute speedup = T_1 / T_2 = 1.91, relative speedup = T_s / T_2 = 1.16</label>
                    <label><input type="radio" name="q92" value="c"> c) Absolute speedup = T_s / T_2 = 1.16, relative speedup = T_1 / T_2 = 1.91</label>
                    <label><input type="radio" name="q92" value="d"> d) Absolute speedup = T_2 / T_s = 0.45, relative speedup = T_2 / T_1 = 0.52</label>
                </div>
                <div class="answer-box" id="answer92" data-correct-answer="c" data-explanation="Absolute speedup compares to best sequential time: T_s/T_2 = 0.52/0.45 ‚âà 1.16. Relative speedup compares parallel versions: T_1/T_2 = 0.86/0.45 ‚âà 1.91.">
                    Correct Answer: c<br><br><em>Explanation: Absolute speedup compares to best sequential time: T_s/T_2 = 0.52/0.45 ‚âà 1.16. Relative speedup compares parallel versions: T_1/T_2 = 0.86/0.45 ‚âà 1.91.</em>
                </div>
            </div>

            <!-- Question 93 -->
            <div class="question">
                <h3>93. Which is true about the efficiency of a parallel program?</h3>
                <div class="options">
                    <label><input type="radio" name="q93" value="a"> a) Efficiency increases as the number of threads decreases</label>
                    <label><input type="radio" name="q93" value="b"> b) Efficiency is the ratio of speedup to the number of processors used</label>
                    <label><input type="radio" name="q93" value="c"> c) Efficiency measures the amount of sequential computation</label>
                    <label><input type="radio" name="q93" value="d"> d) Efficiency does not depend on the problem size</label>
                </div>
                <div class="answer-box" id="answer93" data-correct-answer="b" data-explanation="Efficiency E = S/p, where S is speedup and p is processor count. Measures how effectively processors are utilized; ranges 0 to 1 (100%). E=1 means perfect linear speedup.">
                    Correct Answer: b<br><br><em>Explanation: Efficiency E = S/p, where S is speedup and p is processor count. Measures how effectively processors are utilized; ranges 0 to 1 (100%). E=1 means perfect linear speedup.</em>
                </div>
            </div>

            <!-- Question 94 -->
            <div class="question">
                <h3>94. Which of the following is NOT an overhead in parallel programs?</h3>
                <div class="options">
                    <label><input type="radio" name="q94" value="a"> a) Communication between processes</label>
                    <label><input type="radio" name="q94" value="b"> b) Synchronization between threads</label>
                    <label><input type="radio" name="q94" value="c"> c) Thread creation and termination</label>
                    <label><input type="radio" name="q94" value="d"> d) Sequential execution of a program</label>
                </div>
                <div class="answer-box" id="answer94" data-correct-answer="d" data-explanation="Sequential execution is not an overhead‚Äîit's the baseline. Overheads are additional costs introduced by parallelization: communication, synchronization, thread management, load imbalance, etc.">
                    Correct Answer: d<br><br><em>Explanation: Sequential execution is not an overhead‚Äîit's the baseline. Overheads are additional costs introduced by parallelization: communication, synchronization, thread management, load imbalance, etc.</em>
                </div>
            </div>

            <!-- Question 95 -->
            <div class="question">
                <h3>95. Which formula expresses the 'efficiency' of a parallel program?</h3>
                <div class="options">
                    <label><input type="radio" name="q95" value="a"> a) E = T_parallel / T_serial</label>
                    <label><input type="radio" name="q95" value="b"> b) E = T_serial / T_parallel</label>
                    <label><input type="radio" name="q95" value="c"> c) E = S / p</label>
                    <label><input type="radio" name="q95" value="d"> d) None of above</label>
                </div>
                <div class="answer-box" id="answer95" data-correct-answer="c" data-explanation="Efficiency = Speedup / Number of processors = (T_serial / T_parallel) / p. Indicates how well processors are utilized; 1.0 = perfect utilization.">
                    Correct Answer: c<br><br><em>Explanation: Efficiency = Speedup / Number of processors = (T_serial / T_parallel) / p. Indicates how well processors are utilized; 1.0 = perfect utilization.</em>
                </div>
            </div>

            <!-- Question 96 -->
            <div class="question">
                <h3>96. A parallel program has T_serial = 24ms, p = 8 processors, and T_parallel = 4ms. What is the efficiency of the program?</h3>
                <div class="options">
                    <label><input type="radio" name="q96" value="a"> a) 0.5</label>
                    <label><input type="radio" name="q96" value="b"> b) 0.75</label>
                    <label><input type="radio" name="q96" value="c"> c) 1</label>
                    <label><input type="radio" name="q96" value="d"> d) 8</label>
                </div>
                <div class="answer-box" id="answer96" data-correct-answer="b" data-explanation="S = 24/4 = 6. E = S/p = 6/8 = 0.75 = 75%. Processors are utilized 75% effectively; 25% of potential processing power is lost to overheads.">
                    Correct Answer: b<br><br><em>Explanation: S = 24/4 = 6. E = S/p = 6/8 = 0.75 = 75%. Processors are utilized 75% effectively; 25% of potential processing power is lost to overheads.</em>
                </div>
            </div>

            <!-- Question 97 -->
            <div class="question">
                <h3>97. If efficiency E < 1 in a parallel program, what does this indicate?</h3>
                <div class="options">
                    <label><input type="radio" name="q97" value="a"> a) All processors are fully utilized</label>
                    <label><input type="radio" name="q97" value="b"> b) Processors are not fully used due to overheads</label>
                    <label><input type="radio" name="q97" value="c"> c) The program is running slower than the serial version</label>
                    <label><input type="radio" name="q97" value="d"> d) Linear speedup is achieved</label>
                </div>
                <div class="answer-box" id="answer97" data-correct-answer="b" data-explanation="E < 1 indicates sub-linear speedup: processors are underutilized due to parallel overheads, serial sections, load imbalance, or communication costs.">
                    Correct Answer: b<br><br><em>Explanation: E < 1 indicates sub-linear speedup: processors are underutilized due to parallel overheads, serial sections, load imbalance, or communication costs.</em>
                </div>
            </div>

            <!-- Question 98 -->
            <div class="question">
                <h3>98. A parallel program has T_serial = 24ms, p = 8, and T_parallel = 4ms. How much time is spent on parallel overhead per thread?</h3>
                <div class="options">
                    <label><input type="radio" name="q98" value="a"> a) 1 ms</label>
                    <label><input type="radio" name="q98" value="b"> b) 2 ms</label>
                    <label><input type="radio" name="q98" value="c"> c) 3 ms</label>
                    <label><input type="radio" name="q98" value="d"> d) 4 ms</label>
                </div>
                <div class="answer-box" id="answer98" data-correct-answer="a" data-explanation="Ideal parallel time = T_serial / p = 24/8 = 3ms. Overhead = T_parallel - ideal = 4 - 3 = 1ms per thread (average).">
                    Correct Answer: a<br><br><em>Explanation: Ideal parallel time = T_serial / p = 24/8 = 3ms. Overhead = T_parallel - ideal = 4 - 3 = 1ms per thread (average).</em>
                </div>
            </div>

            <!-- Question 99 -->
            <div class="question">
                <h3>99. What does 'scaled speedup' aim to achieve in parallel systems?</h3>
                <div class="options">
                    <label><input type="radio" name="q99" value="a"> a) Constant problem size with varying processor counts</label>
                    <label><input type="radio" name="q99" value="b"> b) Increase both problem size and the number of processors to maintain efficiency</label>
                    <label><input type="radio" name="q99" value="c"> c) Increase processor count without changing problem size</label>
                    <label><input type="radio" name="q99" value="d"> d) Decrease the problem size while maintaining the number of processors</label>
                </div>
                <div class="answer-box" id="answer99" data-correct-answer="b" data-explanation="Scaled speedup (weak scaling) increases problem size proportionally with processor count to keep per-processor workload constant, measuring ability to solve larger problems.">
                    Correct Answer: b<br><br><em>Explanation: Scaled speedup (weak scaling) increases problem size proportionally with processor count to keep per-processor workload constant, measuring ability to solve larger problems.</em>
                </div>
            </div>

            <!-- Question 100 -->
            <div class="question">
                <h3>100. Which of the following best describes wall clock time in parallel programs?</h3>
                <div class="options">
                    <label><input type="radio" name="q100" value="a"> a) The time spent by the CPU only</label>
                    <label><input type="radio" name="q100" value="b"> b) The total elapsed time from start to finish of execution</label>
                    <label><input type="radio" name="q100" value="c"> c) The time spent on input/output operations only</label>
                    <label><input type="radio" name="q100" value="d"> d) The average time per thread</label>
                </div>
                <div class="answer-box" id="answer100" data-correct-answer="b" data-explanation="Wall clock time (real time) measures total execution time from program start to completion, including all overheads, I/O, and synchronization waits.">
                    Correct Answer: b<br><br><em>Explanation: Wall clock time (real time) measures total execution time from program start to completion, including all overheads, I/O, and synchronization waits.</em>
                </div>
            </div>

            <!-- Question 101 -->
            <div class="question">
                <h3>101. Why shouldn't we compare speedup on different computers?</h3>
                <div class="options">
                    <label><input type="radio" name="q101" value="a"> a) Speedup always grows with more processors</label>
                    <label><input type="radio" name="q101" value="b"> b) Hardware differences can make results wrong</label>
                    <label><input type="radio" name="q101" value="c"> c) Efficiency is always 1 on faster computers</label>
                    <label><input type="radio" name="q101" value="d"> d) Wall clock time doesn't matter</label>
                </div>
                <div class="answer-box" id="answer101" data-correct-answer="b" data-explanation="Speedup is relative to a specific sequential implementation on specific hardware. Different CPUs, memory hierarchies, compilers, etc., affect both T_serial and T_parallel differently, making cross-platform comparisons misleading.">
                    Correct Answer: b<br><br><em>Explanation: Speedup is relative to a specific sequential implementation on specific hardware. Different CPUs, memory hierarchies, compilers, etc., affect both T_serial and T_parallel differently, making cross-platform comparisons misleading.</em>
                </div>
            </div>

            <!-- Question 102 -->
            <div class="question">
                <h3>102. When measuring performance, why run the program multiple times and take the mean or median?</h3>
                <div class="options">
                    <label><input type="radio" name="q102" value="a"> a) To measure I/O speed separately</label>
                    <label><input type="radio" name="q102" value="b"> b) To reduce errors from cold starts, cache misses, and other overheads</label>
                    <label><input type="radio" name="q102" value="c"> c) To make sure CPU usage is consistent</label>
                    <label><input type="radio" name="q102" value="d"> d) To check if speedup is linear with threads</label>
                </div>
                <div class="answer-box" id="answer102" data-correct-answer="b" data-explanation="First runs suffer cold-start effects: cache misses, page faults, JIT compilation, etc. Multiple runs allow warm-up and provide more reliable average performance measurements.">
                    Correct Answer: b<br><br><em>Explanation: First runs suffer cold-start effects: cache misses, page faults, JIT compilation, etc. Multiple runs allow warm-up and provide more reliable average performance measurements.</em>
                </div>
            </div>

            <!-- Question 103 -->
            <div class="question">
                <h3>103. Which following is NOT a source of performance loss in parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q103" value="a"> a) Overhead from process/thread creation and synchronization</label>
                    <label><input type="radio" name="q103" value="b"> b) Load imbalance between threads</label>
                    <label><input type="radio" name="q103" value="c"> c) Non-parallelizable computations (e.g., code dependencies)</label>
                    <label><input type="radio" name="q103" value="d"> d) The ability to increase the number of processors infinitely</label>
                </div>
                <div class="answer-box" id="answer103" data-correct-answer="d" data-explanation="Increasing processors infinitely is not a performance loss‚Äîit's a theoretical consideration. Performance losses come from overheads, imbalance, serial sections, communication, and contention.">
                    Correct Answer: d<br><br><em>Explanation: Increasing processors infinitely is not a performance loss‚Äîit's a theoretical consideration. Performance losses come from overheads, imbalance, serial sections, communication, and contention.</em>
                </div>
            </div>

            <!-- Question 104 -->
            <div class="question">
                <h3>104. What does the term 'contention' refer to in parallel systems?</h3>
                <div class="options">
                    <label><input type="radio" name="q104" value="a"> a) The competition for shared resources, such as memory</label>
                    <label><input type="radio" name="q104" value="b"> b) The synchronization of threads for mutual exclusion</label>
                    <label><input type="radio" name="q104" value="c"> c) The division of work among threads</label>
                    <label><input type="radio" name="q104" value="d"> d) The reduction in processing time with more threads</label>
                </div>
                <div class="answer-box" id="answer104" data-correct-answer="a" data-explanation="Contention occurs when multiple processors simultaneously attempt to access a shared resource (memory bus, network link, cache line, lock), causing delays and reduced performance.">
                    Correct Answer: a<br><br><em>Explanation: Contention occurs when multiple processors simultaneously attempt to access a shared resource (memory bus, network link, cache line, lock), causing delays and reduced performance.</em>
                </div>
            </div>

            <!-- Question 105 -->
            <div class="question">
                <h3>105. Which can contribute to 'idle time' in parallel systems?</h3>
                <div class="options">
                    <label><input type="radio" name="q105" value="a"> a) Threads waiting for synchronization or data from memory</label>
                    <label><input type="radio" name="q105" value="b"> b) Threads executing independently without resource contention</label>
                    <label><input type="radio" name="q105" value="c"> c) Effective load balancing among threads</label>
                    <label><input type="radio" name="q105" value="d"> d) Threads that are fully utilized in computation</label>
                </div>
                <div class="answer-box" id="answer105" data-correct-answer="a" data-explanation="Idle time reduces parallel efficiency. Causes include: waiting at barriers, lock contention, memory latency, I/O operations, load imbalance (fast threads waiting for slow ones).">
                    Correct Answer: a<br><br><em>Explanation: Idle time reduces parallel efficiency. Causes include: waiting at barriers, lock contention, memory latency, I/O operations, load imbalance (fast threads waiting for slow ones).</em>
                </div>
            </div>

            <!-- Question 106 -->
            <div class="question">
                <h3>106. What does Amdahl's Law explain about parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q106" value="a"> a) The importance of memory in parallel programs</label>
                    <label><input type="radio" name="q106" value="b"> b) The maximum achievable speedup based on the serial portion of a program</label>
                    <label><input type="radio" name="q106" value="c"> c) The effect of false sharing on performance</label>
                    <label><input type="radio" name="q106" value="d"> d) The trade-off between computation and communication overhead</label>
                </div>
                <div class="answer-box" id="answer106" data-correct-answer="b" data-explanation="Amdahl's Law: Speedup ‚â§ 1 / (s + (1-s)/p), where s is the serial fraction. It shows that even small serial portions severely limit maximum speedup as p increases.">
                    Correct Answer: b<br><br><em>Explanation: Amdahl's Law: Speedup ‚â§ 1 / (s + (1-s)/p), where s is the serial fraction. It shows that even small serial portions severely limit maximum speedup as p increases.</em>
                </div>
            </div>

            <!-- Question 107 -->
            <div class="question">
                <h3>107. If 80% of a program can be parallelized, what is the maximum possible speedup?</h3>
                <div class="options">
                    <label><input type="radio" name="q107" value="a"> a) 5</label>
                    <label><input type="radio" name="q107" value="b"> b) 8</label>
                    <label><input type="radio" name="q107" value="c"> c) 10</label>
                    <label><input type="radio" name="q107" value="d"> d) 100</label>
                </div>
                <div class="answer-box" id="answer107" data-correct-answer="a" data-explanation="Serial portion = 20% = 0.2. Maximum speedup = 1 / 0.2 = 5 (with infinite processors). This demonstrates Amdahl's Law: serial parts create a hard limit on speedup.">
                    Correct Answer: a<br><br><em>Explanation: Serial portion = 20% = 0.2. Maximum speedup = 1 / 0.2 = 5 (with infinite processors). This demonstrates Amdahl's Law: serial parts create a hard limit on speedup.</em>
                </div>
            </div>

            <!-- Question 108 -->
            <div class="question">
                <h3>108. What is 'strong scalability' in parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q108" value="a"> a) Increasing the number of processors without changing the problem size</label>
                    <label><input type="radio" name="q108" value="b"> b) Increasing the problem size while keeping the number of processors constant</label>
                    <label><input type="radio" name="q108" value="c"> c) Reducing the problem size as the number of processors increases</label>
                    <label><input type="radio" name="q108" value="d"> d) Increasing the number of threads in a single processor</label>
                </div>
                <div class="answer-box" id="answer108" data-correct-answer="a" data-explanation="Strong scaling measures how execution time decreases as more processors are added to a fixed-size problem. Ideal: time halves when processors double.">
                    Correct Answer: a<br><br><em>Explanation: Strong scaling measures how execution time decreases as more processors are added to a fixed-size problem. Ideal: time halves when processors double.</em>
                </div>
            </div>

            <!-- Question 109 -->
            <div class="question">
                <h3>109. What is 'weak scalability' in parallel computing?</h3>
                <div class="options">
                    <label><input type="radio" name="q109" value="a"> a) Increasing the number of processors without increasing the problem size</label>
                    <label><input type="radio" name="q109" value="b"> b) Keeping the problem size constant as the number of processors increases</label>
                    <label><input type="radio" name="q109" value="c"> c) Increasing the problem size in proportion to the number of processors</label>
                    <label><input type="radio" name="q109" value="d"> d) Decreasing problem size as more processors are added</label>
                </div>
                <div class="answer-box" id="answer109" data-correct-answer="c" data-explanation="Weak scaling measures how execution time changes when problem size grows proportionally with processor count. Ideal: time remains constant as problem size and processors increase together.">
                    Correct Answer: c<br><br><em>Explanation: Weak scaling measures how execution time changes when problem size grows proportionally with processor count. Ideal: time remains constant as problem size and processors increase together.</em>
                </div>
            </div>

            <!-- Question 110 -->
            <div class="question">
                <h3>110. What does 'memory vs. parallelism' refer to in performance trade-offs?</h3>
                <div class="options">
                    <label><input type="radio" name="q110" value="a"> a) Using more memory reduces parallelism</label>
                    <label><input type="radio" name="q110" value="b"> b) Maximizing memory use often requires reducing the level of parallelism</label>
                    <label><input type="radio" name="q110" value="c"> c) Memory use is irrelevant in parallel computing</label>
                    <label><input type="radio" name="q110" value="d"> d) Reducing memory usage increases parallelism efficiency</label>
                </div>
                <div class="answer-box" id="answer110" data-correct-answer="b" data-explanation="Parallel algorithms often trade memory for parallelism: replication, padding, or extra data structures reduce contention/false sharing but increase memory usage. Memory bandwidth can also limit parallel scaling.">
                    Correct Answer: b<br><br><em>Explanation: Parallel algorithms often trade memory for parallelism: replication, padding, or extra data structures reduce contention/false sharing but increase memory usage. Memory bandwidth can also limit parallel scaling.</em>
                </div>
            </div>

            <!-- Question 111 -->
            <div class="question">
                <h3>111. What is a common strategy to reduce the impact of communication overhead in parallel systems?</h3>
                <div class="options">
                    <label><input type="radio" name="q111" value="a"> a) Increase the number of threads to perform more computation</label>
                    <label><input type="radio" name="q111" value="b"> b) Overlap communication with computation to hide latency</label>
                    <label><input type="radio" name="q111" value="c"> c) Decrease computation and focus on communication</label>
                    <label><input type="radio" name="q111" value="d"> d) Reduce parallelism to minimize communication</label>
                </div>
                <div class="answer-box" id="answer111" data-correct-answer="b" data-explanation="Overlapping communication with computation (using non-blocking operations, double buffering) allows processors to continue working while data transfers occur, hiding latency and improving efficiency.">
                    Correct Answer: b<br><br><em>Explanation: Overlapping communication with computation (using non-blocking operations, double buffering) allows processors to continue working while data transfers occur, hiding latency and improving efficiency.</em>
                </div>
            </div>

            <!-- Question 112 -->
            <div class="question">
                <h3>112. What is the main difference between sequential and parallel programs?</h3>
                <div class="options">
                    <label><input type="radio" name="q112" value="a"> a) Sequential programs require synchronization, while parallel programs do not</label>
                    <label><input type="radio" name="q112" value="b"> b) Sequential programs focus only on computation, while parallel programs focus on computation and coordination</label>
                    <label><input type="radio" name="q112" value="c"> c) Sequential programs always run faster than parallel programs</label>
                    <label><input type="radio" name="q112" value="d"> d) Parallel programs do not require any computation</label>
                </div>
                <div class="answer-box" id="answer112" data-correct-answer="b" data-explanation="Parallel programs introduce coordination concerns: task decomposition, load balancing, communication, synchronization, and managing shared resources‚Äîcomplexities absent in sequential programming.">
                    Correct Answer: b<br><br><em>Explanation: Parallel programs introduce coordination concerns: task decomposition, load balancing, communication, synchronization, and managing shared resources‚Äîcomplexities absent in sequential programming.</em>
                </div>
            </div>

            <!-- Question 113 -->
            <div class="question">
                <h3>113. In parallel programming, what is a Processing Element (PE)?</h3>
                <div class="options">
                    <label><input type="radio" name="q113" value="a"> a) A physical CPU core in the hardware</label>
                    <label><input type="radio" name="q113" value="b"> b) An abstraction of a core used in programming to divide work</label>
                    <label><input type="radio" name="q113" value="c"> c) The memory unit associated with a thread</label>
                    <label><input type="radio" name="q113" value="d"> d) A special type of parallel algorithm</label>
                </div>
                <div class="answer-box" id="answer113" data-correct-answer="b" data-explanation="A PE is a logical unit of execution (thread, process, or core) in the parallel algorithm. The mapping of PEs to physical cores can vary (one-to-one, many-to-one).">
                    Correct Answer: b<br><br><em>Explanation: A PE is a logical unit of execution (thread, process, or core) in the parallel algorithm. The mapping of PEs to physical cores can vary (one-to-one, many-to-one).</em>
                </div>
            </div>

            <!-- Question 114 -->
            <div class="question">
                <h3>114. In the context of parallel performance, what is scalability?</h3>
                <div class="options">
                    <label><input type="radio" name="q114" value="a"> a) The ability to use more cores without decreasing performance</label>
                    <label><input type="radio" name="q114" value="b"> b) The ability to handle larger datasets efficiently</label>
                    <label><input type="radio" name="q114" value="c"> c) The ability to achieve higher efficiency with more processors</label>
                    <label><input type="radio" name="q114" value="d"> d) The ability to dynamically adjust to different system sizes</label>
                </div>
                <div class="answer-box" id="answer114" data-correct-answer="c" data-explanation="Scalability measures how well parallel performance (speedup, efficiency) improves or maintains as problem size and/or processor count increases. Good scalability means efficiency remains high.">
                    Correct Answer: c<br><br><em>Explanation: Scalability measures how well parallel performance (speedup, efficiency) improves or maintains as problem size and/or processor count increases. Good scalability means efficiency remains high.</em>
                </div>
            </div>

            <!-- Question 115 -->
            <div class="question">
                <h3>115. What does the term 'work decomposition' in parallel computing involve?</h3>
                <div class="options">
                    <label><input type="radio" name="q115" value="a"> a) Allocating work to PEs based on load balancing strategies</label>
                    <label><input type="radio" name="q115" value="b"> b) Dividing the total work among processing elements (PEs)</label>
                    <label><input type="radio" name="q115" value="c"> c) Ensuring that PEs do not communicate with each other</label>
                    <label><input type="radio" name="q115" value="d"> d) Distributing computation across threads dynamically</label>
                </div>
                <div class="answer-box" id="answer115" data-correct-answer="b" data-explanation="Work decomposition (partitioning) splits the computation into tasks that can be assigned to PEs. Good decomposition maximizes parallelism, minimizes dependencies, and balances load.">
                    Correct Answer: b<br><br><em>Explanation: Work decomposition (partitioning) splits the computation into tasks that can be assigned to PEs. Good decomposition maximizes parallelism, minimizes dependencies, and balances load.</em>
                </div>
            </div>

            <!-- Question 116 -->
            <div class="question">
                <h3>116. Which parallel programming pattern is based on breaking down tasks into smaller, independent subtasks that are computed concurrently?</h3>
                <div class="options">
                    <label><input type="radio" name="q116" value="a"> a) Master/Worker</label>
                    <label><input type="radio" name="q116" value="b"> b) Divide and Conquer</label>
                    <label><input type="radio" name="q116" value="c"> c) Data Pipeline</label>
                    <label><input type="radio" name="q116" value="d"> d) Task Parallelism</label>
                </div>
                <div class="answer-box" id="answer116" data-correct-answer="b" data-explanation="Divide and Conquer recursively splits a problem into smaller subproblems, solves them independently (in parallel), then combines results. Classic examples: merge sort, quicksort, matrix multiplication.">
                    Correct Answer: b<br><br><em>Explanation: Divide and Conquer recursively splits a problem into smaller subproblems, solves them independently (in parallel), then combines results. Classic examples: merge sort, quicksort, matrix multiplication.</em>
                </div>
            </div>

            <!-- Question 117 -->
            <div class="question">
                <h3>117. In which parallel programming pattern does the master decompose the problem and distribute tasks among multiple workers?</h3>
                <div class="options">
                    <label><input type="radio" name="q117" value="a"> a) Divide and Conquer</label>
                    <label><input type="radio" name="q117" value="b"> b) Data Pipeline</label>
                    <label><input type="radio" name="q117" value="c"> c) Master/Worker</label>
                    <label><input type="radio" name="q117" value="d"> d) Task Parallelism</label>
                </div>
                <div class="answer-box" id="answer117" data-correct-answer="c" data-explanation="Master/Worker (also called Manager/Worker or Task Farm): master thread coordinates, decomposes work, distributes tasks to worker threads, and collects results. Flexible for irregular workloads.">
                    Correct Answer: c<br><br><em>Explanation: Master/Worker (also called Manager/Worker or Task Farm): master thread coordinates, decomposes work, distributes tasks to worker threads, and collects results. Flexible for irregular workloads.</em>
                </div>
            </div>

            <!-- Question 118 -->
            <div class="question">
                <h3>118. What is the key characteristic of the "Data Pipelining" parallel programming pattern?</h3>
                <div class="options">
                    <label><input type="radio" name="q118" value="a"> a) Tasks are divided and executed sequentially.</label>
                    <label><input type="radio" name="q118" value="b"> b) Tasks are split into independent stages that are executed concurrently.</label>
                    <label><input type="radio" name="q118" value="c"> c) Tasks depend on each other for results.</label>
                    <label><input type="radio" name="q118" value="d"> d) The tasks are executed in a fixed sequence.</label>
                </div>
                <div class="answer-box" id="answer118" data-correct-answer="b" data-explanation="Pipeline parallelism divides computation into stages; each stage processes data and passes it to the next stage. Multiple data items flow through the pipeline concurrently, like an assembly line.">
                    Correct Answer: b<br><br><em>Explanation: Pipeline parallelism divides computation into stages; each stage processes data and passes it to the next stage. Multiple data items flow through the pipeline concurrently, like an assembly line.</em>
                </div>
            </div>

            <!-- Question 119 -->
            <div class="question">
                <h3>119. Which allocation strategy assigns data elements to PEs in a round-robin manner?</h3>
                <div class="options">
                    <label><input type="radio" name="q119" value="a"> a) Block Allocation</label>
                    <label><input type="radio" name="q119" value="b"> b) Block-Cyclic Allocation</label>
                    <label><input type="radio" name="q119" value="c"> c) Cyclic Allocation</label>
                    <label><input type="radio" name="q119" value="d"> d) Data Parallelism</label>
                </div>
                <div class="answer-box" id="answer119" data-correct-answer="c" data-explanation="Cyclic (round-robin) allocation distributes elements one by one to PEs in sequence: PE0 gets element 0, PE1 gets element 1, etc. Good for load balancing when work per element varies.">
                    Correct Answer: c<br><br><em>Explanation: Cyclic (round-robin) allocation distributes elements one by one to PEs in sequence: PE0 gets element 0, PE1 gets element 1, etc. Good for load balancing when work per element varies.</em>
                </div>
            </div>

            <!-- Question 120 -->
            <div class="question">
                <h3>120. Which of the following is an example of a static work allocation strategy?</h3>
                <div class="options">
                    <label><input type="radio" name="q120" value="a"> a) Work Queue</label>
                    <label><input type="radio" name="q120" value="b"> b) Block Allocation</label>
                    <label><input type="radio" name="q120" value="c"> c) Work Pushing</label>
                    <label><input type="radio" name="q120" value="d"> d) Dynamic Work Allocation</label>
                </div>
                <div class="answer-box" id="answer120" data-correct-answer="b" data-explanation="Static allocation decisions are made before execution (at compile or launch time). Block allocation divides array into contiguous chunks assigned to PEs. Simple but can cause load imbalance.">
                    Correct Answer: b<br><br><em>Explanation: Static allocation decisions are made before execution (at compile or launch time). Block allocation divides array into contiguous chunks assigned to PEs. Simple but can cause load imbalance.</em>
                </div>
            </div>

            <!-- Question 121 -->
            <div class="question">
                <h3>121. Which of the following methods is commonly used to achieve dynamic load balancing?</h3>
                <div class="options">
                    <label><input type="radio" name="q121" value="a"> a) Work Queue</label>
                    <label><input type="radio" name="q121" value="b"> b) Cyclic Allocation</label>
                    <label><input type="radio" name="q121" value="c"> c) Block Allocation</label>
                    <label><input type="radio" name="q121" value="d"> d) Block-Cyclic Allocation</label>
                </div>
                <div class="answer-box" id="answer121" data-correct-answer="a" data-explanation="Work queue (task pool): tasks are placed in a shared queue; idle workers take tasks. Enables dynamic load balancing for irregular workloads where task costs vary unpredictably.">
                    Correct Answer: a<br><br><em>Explanation: Work queue (task pool): tasks are placed in a shared queue; idle workers take tasks. Enables dynamic load balancing for irregular workloads where task costs vary unpredictably.</em>
                </div>
            </div>

            <!-- Question 122 -->
            <div class="question">
                <h3>122. Which are the three main phases of the divide-and-conquer paradigm?</h3>
                <div class="options">
                    <label><input type="radio" name="q122" value="a"> a) Divide, Compute, Combine</label>
                    <label><input type="radio" name="q122" value="b"> b) Input, Process, Output</label>
                    <label><input type="radio" name="q122" value="c"> c) Parallelize, Synchronize, Merge</label>
                    <label><input type="radio" name="q122" value="d"> d) Split, Allocate, Finish</label>
                </div>
                <div class="answer-box" id="answer122" data-correct-answer="a" data-explanation="1) Divide: split problem into smaller subproblems. 2) Compute: solve subproblems (recursively or directly). 3) Combine: merge subproblem solutions into final solution.">
                    Correct Answer: a<br><br><em>Explanation: 1) Divide: split problem into smaller subproblems. 2) Compute: solve subproblems (recursively or directly). 3) Combine: merge subproblem solutions into final solution.</em>
                </div>
            </div>

            <!-- Question 123 -->
            <div class="question">
                <h3>123. Which allocation strategy divides a large dataset into fixed-size blocks, each assigned to a different PE?</h3>
                <div class="options">
                    <label><input type="radio" name="q123" value="a"> a) Cyclic Allocation</label>
                    <label><input type="radio" name="q123" value="b"> b) Block Allocation</label>
                    <label><input type="radio" name="q123" value="c"> c) Block-Cyclic Allocation</label>
                    <label><input type="radio" name="q123" value="d"> d) Data Decomposition</label>
                </div>
                <div class="answer-box" id="answer123" data-correct-answer="b" data-explanation="Block allocation partitions data into contiguous blocks of approximately equal size. Simple and provides good locality but may cause load imbalance if work per element varies.">
                    Correct Answer: b<br><br><em>Explanation: Block allocation partitions data into contiguous blocks of approximately equal size. Simple and provides good locality but may cause load imbalance if work per element varies.</em>
                </div>
            </div>

            <!-- Question 124 -->
            <div class="question">
                <h3>124. Which allocation strategy combines aspects of block allocation and cyclic allocation to balance workload and data access?</h3>
                <div class="options">
                    <label><input type="radio" name="q124" value="a"> a) Block Allocation</label>
                    <label><input type="radio" name="q124" value="b"> b) Cyclic Allocation</label>
                    <label><input type="radio" name="q124" value="c"> c) Block-Cyclic Allocation</label>
                    <label><input type="radio" name="q124" value="d"> d) Data Decomposition</label>
                </div>
                <div class="answer-box" id="answer124" data-correct-answer="c" data-explanation="Block-cyclic allocates blocks of B elements cyclically: PE0 gets blocks 0, p, 2p,...; PE1 gets blocks 1, p+1, 2p+1,... Balances locality (within blocks) and load balance.">
                    Correct Answer: c<br><br><em>Explanation: Block-cyclic allocates blocks of B elements cyclically: PE0 gets blocks 0, p, 2p,...; PE1 gets blocks 1, p+1, 2p+1,... Balances locality (within blocks) and load balance.</em>
                </div>
            </div>

            <!-- Question 125 -->
            <div class="question">
                <h3>125. What type of dependence occurs when one statement reads a value written by another statement?</h3>
                <div class="options">
                    <label><input type="radio" name="q125" value="a"> a) True (flow) dependence</label>
                    <label><input type="radio" name="q125" value="b"> b) Anti-dependence</label>
                    <label><input type="radio" name="q125" value="c"> c) Output dependence</label>
                    <label><input type="radio" name="q125" value="d"> d) Loop-carried dependence</label>
                </div>
                <div class="answer-box" id="answer125" data-correct-answer="a" data-explanation="True dependence (Read After Write - RAW): S1 writes X, S2 reads X. S2 depends on S1; must execute after S1. Fundamental dependence that preserves program correctness.">
                    Correct Answer: a<br><br><em>Explanation: True dependence (Read After Write - RAW): S1 writes X, S2 reads X. S2 depends on S1; must execute after S1. Fundamental dependence that preserves program correctness.</em>
                </div>
            </div>

            <!-- Question 126 -->
            <div class="question">
                <h3>126. What type of dependence occurs when a statement writes a variable that was previously read by another statement?</h3>
                <div class="options">
                    <label><input type="radio" name="q126" value="a"> a) True (flow) dependence</label>
                    <label><input type="radio" name="q126" value="b"> b) Anti-dependence</label>
                    <label><input type="radio" name="q126" value="c"> c) Output dependence</label>
                    <label><input type="radio" name="q126" value="d"> d) Control dependence</label>
                </div>
                <div class="answer-box" id="answer126" data-correct-answer="b" data-explanation="Anti-dependence (Write After Read - WAR): S1 reads X, S2 writes X. S2 must not overwrite X before S1 reads it. Can often be eliminated by renaming variables.">
                    Correct Answer: b<br><br><em>Explanation: Anti-dependence (Write After Read - WAR): S1 reads X, S2 writes X. S2 must not overwrite X before S1 reads it. Can often be eliminated by renaming variables.</em>
                </div>
            </div>

            <!-- Question 127 -->
            <div class="question">
                <h3>127. What type of dependence occurs when two statements write to the same variable and the order of writes affects the final result?</h3>
                <div class="options">
                    <label><input type="radio" name="q127" value="a"> a) Anti-dependence</label>
                    <label><input type="radio" name="q127" value="b"> b) True (flow) dependence</label>
                    <label><input type="radio" name="q127" value="c"> c) Output dependence</label>
                    <label><input type="radio" name="q127" value="d"> d) Loop-carried dependence</label>
                </div>
                <div class="answer-box" id="answer127" data-correct-answer="c" data-explanation="Output dependence (Write After Write - WAW): S1 writes X, S2 writes X. The final value of X depends on which write occurs last. Can often be eliminated by renaming.">
                    Correct Answer: c<br><br><em>Explanation: Output dependence (Write After Write - WAW): S1 writes X, S2 writes X. The final value of X depends on which write occurs last. Can often be eliminated by renaming.</em>
                </div>
            </div>

            <!-- Question 128 -->
            <div class="question">
                <h3>128. What is the typical cause of "loop-carried dependence" in parallel loops?</h3>
                <div class="options">
                    <label><input type="radio" name="q128" value="a"> a) Memory access conflicts</label>
                    <label><input type="radio" name="q128" value="b"> b) Data dependency between iterations</label>
                    <label><input type="radio" name="q128" value="c"> c) Inefficient task decomposition</label>
                    <label><input type="radio" name="q128" value="d"> d) Poor data locality</label>
                </div>
                <div class="answer-box" id="answer128" data-correct-answer="b" data-explanation="Loop-carried dependence occurs when iteration i depends on data produced in iteration j (j < i). This serializes the loop, preventing parallel execution across iterations.">
                    Correct Answer: b<br><br><em>Explanation: Loop-carried dependence occurs when iteration i depends on data produced in iteration j (j < i). This serializes the loop, preventing parallel execution across iterations.</em>
                </div>
            </div>

            <!-- Question 129 -->
            <div class="question">
                <h3>129. Which statement best describes work stealing in dynamic work allocation?</h3>
                <div class="options">
                    <label><input type="radio" name="q129" value="a"> a) An idle PE takes work from another PE's queue</label>
                    <label><input type="radio" name="q129" value="b"> b) A busy PE actively sends tasks to other PEs</label>
                    <label><input type="radio" name="q129" value="c"> c) Tasks are assigned once at the beginning of execution</label>
                    <label><input type="radio" name="q129" value="d"> d) Each PE executes the same task on different data</label>
                </div>
                <div class="answer-box" id="answer129" data-correct-answer="a" data-explanation="Work stealing: idle processors "steal" tasks from busy processors' work queues. Efficient for dynamic load balancing with low overhead; used in modern parallel frameworks like Cilk, Java Fork-Join.">
                    Correct Answer: a<br><br><em>Explanation: Work stealing: idle processors "steal" tasks from busy processors' work queues. Efficient for dynamic load balancing with low overhead; used in modern parallel frameworks like Cilk, Java Fork-Join.</em>
                </div>
            </div>

            <!-- Question 130 -->
            <div class="question">
                <h3>130. Which statement best describes work pushing in dynamic work allocation?</h3>
                <div class="options">
                    <label><input type="radio" name="q130" value="a"> a) An idle PE takes work from another PE's queue</label>
                    <label><input type="radio" name="q130" value="b"> b) A busy PE actively sends tasks to other PEs</label>
                    <label><input type="radio" name="q130" value="c"> c) Tasks are assigned once at the beginning of execution</label>
                    <label><input type="radio" name="q130" value="d"> d) Each PE executes the same task on different data</label>
                </div>
                <div class="answer-box" id="answer130" data-correct-answer="b" data-explanation="Work pushing: overloaded processors push tasks to idle ones. Requires knowledge of others' load. Can cause contention and is less common than work stealing in modern systems.">
                    Correct Answer: b<br><br><em>Explanation: Work pushing: overloaded processors push tasks to idle ones. Requires knowledge of others' load. Can cause contention and is less common than work stealing in modern systems.</em>
                </div>
            </div>

            <!-- Question 131 -->
            <div class="question">
                <h3>131. To improve performance in parallel programs, we should focus on:</h3>
                <div class="options">
                    <label><input type="radio" name="q131" value="a"> a) Reducing dependences</label>
                    <label><input type="radio" name="q131" value="b"> b) Choosing proper granularity</label>
                    <label><input type="radio" name="q131" value="c"> c) Improving data locality</label>
                    <label><input type="radio" name="q131" value="d"> d) All of the above</label>
                </div>
                <div class="answer-box" id="answer131" data-correct-answer="d" data-explanation="All three are crucial: 1) Reduce dependences to enable more parallelism. 2) Choose proper task granularity to balance overhead and parallelism. 3) Improve locality to reduce communication/cache misses.">
                    Correct Answer: d<br><br><em>Explanation: All three are crucial: 1) Reduce dependences to enable more parallelism. 2) Choose proper task granularity to balance overhead and parallelism. 3) Improve locality to reduce communication/cache misses.</em>
                </div>
            </div>
        </div>

        <!-- Slides Section -->
        <div class="slides-section hidden" id="slides-section">
            <div class="slides-header">
                ÿ≥ŸÑÿßŸäÿØÿßÿ™ ÿßŸÑŸÖÿßÿØÿ©
            </div>
            
            <div class="pdf-controls">
                <button class="pdf-btn active" onclick="loadLecture(0)">
                    <span>üìÑ</span> Lecture 1
                </button>
                <button class="pdf-btn" onclick="loadLecture(1)">
                    <span>üìÑ</span> Lecture 2
                </button>
                <button class="pdf-btn" onclick="loadLecture(2)">
                    <span>üìÑ</span> Lecture 3-4
                </button>
                <button class="pdf-btn" onclick="loadLecture(3)">
                    <span>üìÑ</span> Lecture 5
                </button>
                <button class="pdf-btn" onclick="loadLecture(4)">
                    <span>üìÑ</span> Lecture 6
                </button>
                <button class="pdf-btn" onclick="loadLecture(5)">
                    <span>üìÑ</span> Lecture 7
                </button>
            </div>

            <!-- Desktop PDF Viewer -->
            <div class="pdf-viewer-container desktop-viewer">
                <div class="pdf-viewer-header">
                    <div class="pdf-viewer-title" id="pdf-title">Lecture 1</div>
                    <div class="pdf-controls-small">
                        <button class="pdf-nav-btn" onclick="downloadPdf()" title="Download">‚§ì</button>
                    </div>
                </div>
                <div class="pdf-frame-container">
                    <div class="pdf-loading" id="pdf-loading">
                        <div class="pdf-loading-spinner"></div>
                        <div class="pdf-loading-text">Loading PDF...</div>
                    </div>
                    <iframe class="pdf-frame" id="pdf-frame" src="Lecture1.pdf" frameborder="0"></iframe>
                </div>
            </div>

            <!-- Mobile PDF List -->
            <div class="mobile-pdf-list">
                <!-- Lecture 1 -->
                <div class="mobile-pdf-item">
                    <div class="mobile-pdf-info">
                        <div class="mobile-pdf-icon">üìÑ</div>
                        <div class="mobile-pdf-details">
                            <div class="mobile-pdf-name">Lecture 1</div>
                            <div class="mobile-pdf-size">PDF</div>
                        </div>
                    </div>
                    <div class="mobile-pdf-actions">
                        <button class="mobile-pdf-btn open-btn" onclick="openPdfMobile('Lecture1.pdf')">Open</button>
                    </div>
                </div>
                
                <!-- Lecture 2 -->
                <div class="mobile-pdf-item">
                    <div class="mobile-pdf-info">
                        <div class="mobile-pdf-icon">üìÑ</div>
                        <div class="mobile-pdf-details">
                            <div class="mobile-pdf-name">Lecture 2</div>
                            <div class="mobile-pdf-size">PDF</div>
                        </div>
                    </div>
                    <div class="mobile-pdf-actions">
                        <button class="mobile-pdf-btn open-btn" onclick="openPdfMobile('Lecture2.pdf')">Open</button>
                    </div>
                </div>
                
                <!-- Lecture 3-4 -->
                <div class="mobile-pdf-item">
                    <div class="mobile-pdf-info">
                        <div class="mobile-pdf-icon">üìÑ</div>
                        <div class="mobile-pdf-details">
                            <div class="mobile-pdf-name">Lecture 3-4</div>
                            <div class="mobile-pdf-size">PDF</div>
                        </div>
                    </div>
                    <div class="mobile-pdf-actions">
                        <button class="mobile-pdf-btn open-btn" onclick="openPdfMobile('Lecture3-4.pdf')">Open</button>
                    </div>
                </div>
                
                <!-- Lecture 5 -->
                <div class="mobile-pdf-item">
                    <div class="mobile-pdf-info">
                        <div class="mobile-pdf-icon">üìÑ</div>
                        <div class="mobile-pdf-details">
                            <div class="mobile-pdf-name">Lecture 5</div>
                            <div class="mobile-pdf-size">PDF</div>
                        </div>
                    </div>
                    <div class="mobile-pdf-actions">
                        <button class="mobile-pdf-btn open-btn" onclick="openPdfMobile('Lecture5.pdf')">Open</button>
                    </div>
                </div>
                
                <!-- Lecture 6 -->
                <div class="mobile-pdf-item">
                    <div class="mobile-pdf-info">
                        <div class="mobile-pdf-icon">üìÑ</div>
                        <div class="mobile-pdf-details">
                            <div class="mobile-pdf-name">Lecture 6</div>
                            <div class="mobile-pdf-size">PDF</div>
                        </div>
                    </div>
                    <div class="mobile-pdf-actions">
                        <button class="mobile-pdf-btn open-btn" onclick="openPdfMobile('Lecture6.pdf')">Open</button>
                    </div>
                </div>
                
                <!-- Lecture 7 -->
                <div class="mobile-pdf-item">
                    <div class="mobile-pdf-info">
                        <div class="mobile-pdf-icon">üìÑ</div>
                        <div class="mobile-pdf-details">
                            <div class="mobile-pdf-name">Lecture 7</div>
                            <div class="mobile-pdf-size">PDF</div>
                        </div>
                    </div>
                    <div class="mobile-pdf-actions">
                        <button class="mobile-pdf-btn open-btn" onclick="openPdfMobile('Lecture7.pdf')">Open</button>
                    </div>
                </div>
            </div>
            
            <div class="controls">
                <button class="btn" onclick="toggleSlides()">
                    <span class="btn-icon">‚Üê</span> ÿßŸÑÿπŸàÿØÿ© ÿ•ŸÑŸâ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ©
                </button>
            </div>
        </div>

        <div class="footer-note">
            ÿØÿπŸàÿßÿ™ŸÉŸÖ ŸÑŸÑŸÖÿ≥ÿßÿπÿØ ÿßŸÑÿÆŸÅŸä ŸàÿßŸÑÿπÿßŸÖŸÑŸäŸÜ ÿπŸÑŸâ ÿßŸÑŸÖŸàŸÇÿπ ÿ®ÿßŸÑÿ™ŸàŸÅŸäŸÇ ŸàÿßŸÑÿ≥ÿØÿßÿØ ŸàÿßŸÑÿ≤Ÿàÿ¨ÿ© ÿßŸÑÿµÿßŸÑÿ≠ÿ©
        </div>
    </div>

    <script>
        // Quiz Data - Answers for all 129 questions
        const correctAnswers = {
            q1: 'a', q2: 'b', q3: 'c', q4: 'c', q5: 'b', q6: 'b', q7: 'b',
            q8: 'c', q9: 'c', q10: 'd', q11: 'b', q12: 'c', q13: 'd',
            q14: 'a', q15: 'b', q16: 'c', q17: 'd', q18: 'b', q19: 'b',
            q20: 'b', q21: 'a', q22: 'b', q23: 'c', q24: 'a', q25: 'b',
            q26: 'b', q27: 'a', q28: 'b', q30: 'b', q31: 'd', q32: 'c',
            q33: 'a', q34: 'c', q35: 'b', q36: 'b', q37: 'c', q38: 'c',
            q39: 'b', q40: 'b', q41: 'b', q42: 'a', q43: 'b', q44: 'c',
            q45: 'a', q46: 'd', q47: 'b', q48: 'b', q49: 'd', q50: 'c',
            q51: 'c', q52: 'b', q53: 'c', q54: 'b', q55: 'd', q56: 'b',
            q57: 'b', q58: 'b', q59: 'c', q60: 'c', q61: 'a', q62: 'b',
            q64: 'c', q65: 'b', q66: 'b', q67: 'c', q68: 'c', q69: 'a',
            q70: 'd', q71: 'b', q72: 'b', q73: 'b', q74: 'b', q75: 'b',
            q76: 'c', q77: 'b', q78: 'b', q79: 'c', q80: 'b', q81: 'a',
            q82: 'b', q83: 'b', q84: 'd', q85: 'b', q86: 'c', q87: 'b',
            q88: 'c', q89: 'b', q90: 'a', q91: 'a', q92: 'c', q93: 'b',
            q94: 'd', q95: 'c', q96: 'b', q97: 'b', q98: 'a', q99: 'b',
            q100: 'b', q101: 'b', q102: 'b', q103: 'd', q104: 'a', q105: 'a',
            q106: 'b', q107: 'a', q108: 'a', q109: 'c', q110: 'b', q111: 'b',
            q112: 'b', q113: 'b', q114: 'c', q115: 'b', q116: 'b', q117: 'c',
            q118: 'b', q119: 'c', q120: 'b', q121: 'a', q122: 'a', q123: 'b',
            q124: 'c', q125: 'a', q126: 'b', q127: 'c', q128: 'b', q129: 'a',
            q130: 'b', q131: 'd'
        };

        // Lectures data
        const lectures = [
            { name: "Lecture 1", pdf: "Lecture1.pdf" },
            { name: "Lecture 2", pdf: "Lecture2.pdf" },
            { name: "Lecture 3-4", pdf: "Lecture3-4.pdf" },
            { name: "Lecture 5", pdf: "Lecture5.pdf" },
            { name: "Lecture 6", pdf: "Lecture6.pdf" },
            { name: "Lecture 7", pdf: "Lecture7.pdf" }
        ];

        let currentPdf = 'Lecture1.pdf';
        let currentLectureIndex = 0;

        // Quiz functionality
        function resetQuiz() {
            const radioButtons = document.querySelectorAll('input[type="radio"]');
            radioButtons.forEach(radio => radio.checked = false);

            const answerBoxes = document.querySelectorAll('.answer-box');
            answerBoxes.forEach(box => {
                box.style.display = 'none';
                box.classList.remove('correct', 'incorrect');
                const originalHTML = box.getAttribute('data-original-html') || box.innerHTML;
                box.innerHTML = originalHTML;
            });

            updateProgress();
        }

        function showAllAnswers() {
            const questions = document.querySelectorAll('.question');
            
            questions.forEach(questionContainer => {
                const answerBox = questionContainer.querySelector('.answer-box');
                if (!answerBox) return;

                const correctAnswer = answerBox.getAttribute('data-correct-answer');
                const explanation = answerBox.getAttribute('data-explanation') || '';
                
                const correctInput = questionContainer.querySelector(`input[value="${correctAnswer}"]`);
                if (correctInput) correctInput.checked = true;

                answerBox.innerHTML = `
                    ‚úÖ Correct Answer: ${correctAnswer}
                    <div class="explanation-container">
                        <div class="explanation-content" style="display:block;">
                            ${explanation}
                        </div>
                    </div>
                `;
                answerBox.style.display = 'block';
                answerBox.classList.add('correct');
                answerBox.classList.remove('incorrect');
            });
            updateProgress();
        }

        function hideAllAnswers() {
            const answerBoxes = document.querySelectorAll('.answer-box');
            answerBoxes.forEach(box => {
                box.style.display = 'none';
                box.classList.remove('correct', 'incorrect');
            });
        }

        function updateProgress() {
            const radioButtons = document.querySelectorAll('input[type="radio"]:checked');
            const answeredCount = radioButtons.length;
            const progressPercent = Math.round((answeredCount / 129) * 100);
            
            document.getElementById('answered-count').textContent = answeredCount;
            document.getElementById('quiz-progress').style.width = `${progressPercent}%`;
        }

        // Theme toggle
        function toggleTheme() {
            const body = document.body;
            const themeToggle = document.getElementById('themeToggle');
            
            if(body.getAttribute('data-theme') === 'dark') {
                body.removeAttribute('data-theme');
                themeToggle.innerHTML = '<span class="btn-icon">üåô</span> Dark Mode';
                localStorage.setItem('theme', 'light');
            } else {
                body.setAttribute('data-theme', 'dark');
                themeToggle.innerHTML = '<span class="btn-icon">‚òÄÔ∏è</span> Light Mode';
                localStorage.setItem('theme', 'dark');
            }
        }

        // Slides toggle
        let slidesVisible = false;
        function toggleSlides() {
            const slidesSection = document.getElementById('slides-section');
            const slidesToggle = document.getElementById('slidesToggle');
            const questionsSection = document.getElementById('questions-section');
            
            if(!slidesVisible) {
                slidesSection.classList.remove('hidden');
                questionsSection.style.display = 'none';
                slidesToggle.innerHTML = '<span class="btn-icon">üìù</span> ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ©';
                slidesVisible = true;
                slidesSection.scrollIntoView({ behavior: 'smooth' });
            } else {
                slidesSection.classList.add('hidden');
                questionsSection.style.display = 'block';
                slidesToggle.innerHTML = '<span class="btn-icon">üìö</span> ÿ≥ŸÑÿßŸäÿØÿßÿ™ ÿßŸÑŸÖÿßÿØÿ©';
                slidesVisible = false;
                window.scrollTo({ top: 0, behavior: 'smooth' });
            }
        }

        // PDF functionality
        function loadPdf(pdfFile, title) {
            currentPdf = pdfFile;
            
            document.getElementById('pdf-title').textContent = title;
            
            const loading = document.getElementById('pdf-loading');
            const frame = document.getElementById('pdf-frame');
            
            loading.style.display = 'flex';
            frame.style.display = 'none';
            
            frame.src = pdfFile;
            
            frame.onload = function() {
                setTimeout(() => {
                    loading.style.display = 'none';
                    frame.style.display = 'block';
                }, 500);
            };
        }

        function loadLecture(index) {
            currentLectureIndex = index;
            const lecture = lectures[index];
            
            document.querySelectorAll('.pdf-btn').forEach(btn => {
                btn.classList.remove('active');
            });
            event.target.classList.add('active');
            
            loadPdf(lecture.pdf, lecture.name);
        }

        function downloadPdf() {
            const link = document.createElement('a');
            link.href = currentPdf;
            link.download = currentPdf;
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
        }

        // Mobile PDF functions
        function openPdfMobile(pdfFile) {
            window.open(pdfFile, '_blank');
        }

        // Event listeners for radio buttons
        document.addEventListener('DOMContentLoaded', () => {
            const radioButtons = document.querySelectorAll('input[type="radio"]');
            radioButtons.forEach(radio => {
                radio.addEventListener('change', (e) => {
                    const questionNumber = e.target.name.substring(1);
                    const answerBox = document.getElementById(`answer${questionNumber}`);
                    const questionContainer = e.target.closest('.question');
                    
                    if (!answerBox.getAttribute('data-original-html')) {
                        answerBox.setAttribute('data-original-html', answerBox.innerHTML);
                    }
                    
                    const originalHTML = answerBox.getAttribute('data-original-html');
                    const userAnswer = e.target.value;
                    const correctAnswer = correctAnswers[`q${questionNumber}`];
                    const explanation = answerBox.getAttribute('data-explanation') || '';

                    questionContainer.classList.remove('answered-correct', 'answered-incorrect');

                    if (userAnswer === correctAnswer) {
                        answerBox.innerHTML = `
                            ‚úÖ Correct!
                            <div class="explanation-container">
                                <button class="btn-explanation" onclick="this.parentElement.querySelector('.explanation-content').style.display='block'; this.style.display='none';">
                                    <span style="font-size:1.1em">üí°</span> Show Explanation
                                </button>
                                <div class="explanation-content" style="display:none;">
                                    ${explanation}
                                </div>
                            </div>
                        `;
                        answerBox.classList.add('correct');
                        answerBox.classList.remove('incorrect');
                    } else {
                        answerBox.innerHTML = `
                            ‚ùå Incorrect.
                            <button class="btn-show-correct" onclick="this.nextElementSibling.style.display='block'; this.style.display='none';">
                                Show Correct Choice
                            </button>
                            <div class="reveal-content" style="display:none; margin-top:10px;">
                                <div style="margin-bottom:10px; font-weight:bold;">Correct Answer: ${correctAnswer}</div>
                                <div class="explanation-content" style="display:block;">
                                    ${explanation}
                                </div>
                            </div>
                        `;
                        answerBox.classList.add('incorrect');
                        answerBox.classList.remove('correct');
                    }
                    answerBox.style.display = 'block';
                    
                    updateProgress();
                });
            });

            // Initialize theme
            const savedTheme = localStorage.getItem('theme') || 'light';
            const themeToggle = document.getElementById('themeToggle');
            
            if(savedTheme === 'dark') {
                document.body.setAttribute('data-theme', 'dark');
                themeToggle.innerHTML = '<span class="btn-icon">‚òÄÔ∏è</span> Light Mode';
            }
            
            // Store original HTML for all answer boxes
            const answerBoxes = document.querySelectorAll('.answer-box');
            answerBoxes.forEach(box => {
                if (!box.getAttribute('data-original-html')) {
                    box.setAttribute('data-original-html', box.innerHTML);
                }
            });
            
            // Initialize PDF viewer
            const frame = document.getElementById('pdf-frame');
            frame.onload = function() {
                setTimeout(() => {
                    document.getElementById('pdf-loading').style.display = 'none';
                    frame.style.display = 'block';
                }, 800);
            };
        });
    </script>
</body>
</html>